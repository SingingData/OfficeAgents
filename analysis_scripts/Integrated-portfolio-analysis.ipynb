{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29353ae9",
   "metadata": {},
   "source": [
    "# Portfolio File Clean Up from Static Download\n",
    "\n",
    "This notebook demonstrates an interactive way to use code in Github to analyze and generate revised output based on the most recent static portfolio download.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8df74b",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "First, let's import our modules and set up the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17123a24",
   "metadata": {},
   "source": [
    "### Check and Install Missing Packages and Requirements\n",
    "Let's check which packages are missing and install them if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b20807a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:21.238463Z",
     "iopub.status.busy": "2025-11-15T17:07:21.238463Z",
     "iopub.status.idle": "2025-11-15T17:07:29.712559Z",
     "shell.execute_reply": "2025-11-15T17:07:29.712559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Package installation examples shown above!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install from requirements file\n",
    "%pip install -q -r requirements.txt\n",
    "\n",
    "print(\"‚úÖ Package installation examples shown above!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298cd64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:29.716424Z",
     "iopub.status.busy": "2025-11-15T17:07:29.716424Z",
     "iopub.status.idle": "2025-11-15T17:07:54.998414Z",
     "shell.execute_reply": "2025-11-15T17:07:54.998414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking package availability...\n",
      "--------------------------------------------------\n",
      "‚úÖ numpy is available\n",
      "‚úÖ numpy is available\n",
      "‚úÖ pandas is available\n",
      "‚úÖ pandas is available\n",
      "‚úÖ matplotlib is available\n",
      "‚úÖ plotly is available\n",
      "‚úÖ matplotlib is available\n",
      "‚úÖ plotly is available\n",
      "‚úÖ scikit-learn is available\n",
      "‚úÖ ipython is available\n",
      "‚úÖ scikit-learn is available\n",
      "‚úÖ ipython is available\n",
      "‚úÖ yfinance is available\n",
      "‚úÖ yfinance is available\n",
      "‚úÖ openpyxl is available\n",
      "‚úÖ pickleshare is available\n",
      "‚úÖ openpyxl is available\n",
      "‚úÖ pickleshare is available\n",
      "‚úÖ requests is available\n",
      "‚úÖ python-dotenv is available\n",
      "‚úÖ requests is available\n",
      "‚úÖ python-dotenv is available\n",
      "‚úÖ openai is available\n",
      "‚úÖ schedule is available\n",
      "‚úÖ datetime is available\n",
      "--------------------------------------------------\n",
      "üéâ All packages are available!\n",
      "‚úÖ openai is available\n",
      "‚úÖ schedule is available\n",
      "‚úÖ datetime is available\n",
      "--------------------------------------------------\n",
      "üéâ All packages are available!\n",
      "Requirement already satisfied: python-docx in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Package installation examples shown above!\n",
      "Requirement already satisfied: python-docx in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Package installation examples shown above!\n",
      "‚úÖ Basic imports successful!\n",
      "üìÅ Current directory: c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\n",
      "üêç Python version: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]\n",
      "repo_root is c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\n",
      "‚úÖ Basic imports successful!\n",
      "üìÅ Current directory: c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\n",
      "üêç Python version: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]\n",
      "repo_root is c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which packages are available and install missing ones\n",
    "\n",
    "\n",
    "def check_and_install_package(package_name, import_name=None):\n",
    "    \"\"\"Check if a package is available, install if missing\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"‚úÖ {package_name} is available\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package_name} is missing - installing...\")\n",
    "        try:\n",
    "            import subprocess\n",
    "            result = subprocess.run([sys.executable, '-m', 'pip', 'install', package_name], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ Successfully installed {package_name}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Failed to install {package_name}: {result.stderr}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"üí• Error installing {package_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "# List of packages your notebook needs\n",
    "packages_to_check = [\n",
    "    ('numpy', 'numpy'),\n",
    "    ('pandas', 'pandas'), \n",
    "    ('matplotlib', 'matplotlib'),\n",
    "    ('plotly', 'plotly'),\n",
    "    ('scikit-learn', 'sklearn'),\n",
    "    ('ipython', 'IPython'),\n",
    "    ('yfinance', 'yfinance'),  \n",
    "    ('openpyxl', 'openpyxl'),\n",
    "    ('pickleshare','pickleshare'),\n",
    "    ('requests','requests'),\n",
    "    ('python-dotenv','dotenv'),\n",
    "    ('openai','openai'),\n",
    "    ('schedule','schedule'),\n",
    "    ('datetime','datetime'),\n",
    "]\n",
    "\n",
    "print(\"üîç Checking package availability...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "missing_packages = []\n",
    "for package_name, import_name in packages_to_check:\n",
    "    if not check_and_install_package(package_name, import_name):\n",
    "        missing_packages.append(package_name)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if missing_packages:\n",
    "    print(f\"‚ö†Ô∏è Some packages couldn't be installed: {missing_packages}\")\n",
    "else:\n",
    "    print(\"üéâ All packages are available!\")\n",
    "\n",
    "%pip install python-docx\n",
    "print(\"‚úÖ Package installation examples shown above!\")\n",
    "\n",
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from time import time\n",
    "np.random.seed(10)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "print(\"‚úÖ Basic imports successful!\")\n",
    "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "\n",
    "# Load environment variables from the root repo .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Get the repo root (adjust as needed)\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd()))\n",
    "print(f'repo_root is {REPO_ROOT}')\n",
    "dotenv_path = os.path.join(REPO_ROOT, \".env\")\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475de44",
   "metadata": {},
   "source": [
    "### GitHubCodeRunner Class to Link to a Github Site\n",
    "Let's define our main class in a more modular way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c020cdd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.009774Z",
     "iopub.status.busy": "2025-11-15T17:07:55.009774Z",
     "iopub.status.idle": "2025-11-15T17:07:55.074784Z",
     "shell.execute_reply": "2025-11-15T17:07:55.072733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GitHubCodeRunner class defined!\n"
     ]
    }
   ],
   "source": [
    "class GitHubCodeRunner:\n",
    "    \"\"\"\n",
    "    Interactive GitHub repository operations and Python code execution.\n",
    "    Perfect for Jupyter notebook usage!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, workspace_dir: str = \"./workspace\"):\n",
    "        \"\"\"Initialize with a local workspace directory.\"\"\"\n",
    "        self.workspace_dir = workspace_dir\n",
    "        self.repos_dir = os.path.join(workspace_dir, \"github_repos\")\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs(self.repos_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"üöÄ GitHubCodeRunner initialized!\")\n",
    "        print(f\"üìÇ Workspace: {self.workspace_dir}\")\n",
    "        print(f\"üìÅ Repos directory: {self.repos_dir}\")\n",
    "    \n",
    "    def create_demo_files(self):\n",
    "        \"\"\"Create sample Python files for testing.\"\"\"\n",
    "        demo_dir = os.path.join(self.repos_dir, \"demo_scripts\")\n",
    "        os.makedirs(demo_dir, exist_ok=True)\n",
    "        \n",
    "        # Simple hello world script\n",
    "        hello_script = '''#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "print(\"Hello from Jupyter notebook execution!\")\n",
    "print(\"This script was run interactively\")\n",
    "\n",
    "# Print python version info\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info\")\n",
    "print(sys.version_info)\n",
    "\n",
    "# Identify working directory for source data\n",
    "source_dir = os.getcwd()\n",
    "print(f\"Source directory: {source_dir}\")\n",
    "   \n",
    "'''\n",
    "        \n",
    "        # Data processing script\n",
    "        data_script = '''#!/usr/bin/env python3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"[DATA] Processing sample data...\")\n",
    "\n",
    "data = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"items\": [i * 2 for i in range(5)],\n",
    "    \"total\": sum(i * 2 for i in range(5))\n",
    "}\n",
    "\n",
    "print(f\"Processed {len(data['items'])} items\")\n",
    "print(f\"Total: {data['total']}\")\n",
    "print(\"‚úÖ Data processing complete!\")\n",
    "'''\n",
    "        \n",
    "        # Write files\n",
    "        scripts = {\n",
    "                        \"hello_world.py\": hello_script,\n",
    "                        \"data_processor.py\": data_script\n",
    "                    }\n",
    "                    \n",
    "        for filename, content in scripts.items():\n",
    "                        filepath = os.path.join(demo_dir, filename)\n",
    "                        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                            f.write(content)\n",
    "                        print(f\"‚úÖ Created: {filename}\")\n",
    "                    \n",
    "        return demo_dir\n",
    "    \n",
    "    def list_python_files(self, directory):\n",
    "        \"\"\"List all Python files in a directory.\"\"\"\n",
    "        python_files = []\n",
    "        \n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith('.py'):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    python_files.append({\n",
    "                        'filename': file,\n",
    "                        'path': full_path,\n",
    "                        'size': os.path.getsize(full_path)\n",
    "                    })\n",
    "        \n",
    "        return python_files\n",
    "    \n",
    "    def execute_script(self, script_path):\n",
    "        \"\"\"Execute a Python script and return results.\"\"\"\n",
    "        print(f\"üöÄ Executing: {os.path.basename(script_path)}\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, script_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"‚úÖ Execution successful!\")\n",
    "                if result.stdout:\n",
    "                    print(\"üìÑ Output:\")\n",
    "                    print(result.stdout)\n",
    "                return True, result.stdout\n",
    "            else:\n",
    "                print(f\"‚ùå Execution failed (code: {result.returncode})\")\n",
    "                if result.stderr:\n",
    "                    print(\"üìÑ Error:\")\n",
    "                    print(result.stderr)\n",
    "                return False, result.stderr\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üí• Exception: {e}\")\n",
    "            return False, str(e)\n",
    "    \n",
    "    def sync_and_push(self, repo_path, commit_message=\"Auto-commit from notebook\"):\n",
    "        \"\"\"Pull, add all changes, commit, and push to GitHub.\"\"\"\n",
    "        import subprocess\n",
    "        import os\n",
    "        \n",
    "        original_dir = os.getcwd()\n",
    "        try:\n",
    "            os.chdir(repo_path)\n",
    "            \n",
    "            # Add changes first\n",
    "            print(\"üìù Adding all changes...\")\n",
    "            subprocess.run(['git', 'add', '.'], check=True)\n",
    "            \n",
    "            # Commit before pulling\n",
    "            print(\"üíæ Committing local changes...\")\n",
    "            result = subprocess.run(['git', 'commit', '-m', commit_message], \n",
    "                                capture_output=True, text=True)\n",
    "            if 'nothing to commit' in result.stdout:\n",
    "                print(\"‚ÑπÔ∏è No new changes to commit\")\n",
    "            else:\n",
    "                print(\"‚úÖ Committed\")\n",
    "            \n",
    "            # Pull latest changes with merge strategy (simpler and safer)\n",
    "            print(\"üì• Pulling latest changes...\")\n",
    "            subprocess.run(['git', 'pull'], check=True)\n",
    "            print(\"‚úÖ Pulled successfully\")\n",
    "            \n",
    "            # Push to GitHub\n",
    "            print(\"üì§ Pushing to GitHub...\")\n",
    "            subprocess.run(['git', 'push'], check=True)\n",
    "            \n",
    "            print(\"‚úÖ Successfully synced with GitHub!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            print(\"\\nüí° Manual fix:\")\n",
    "            print(f\"   cd {repo_path}\")\n",
    "            print(\"   git status\")\n",
    "            return False\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "    \n",
    "    def push_to_github(self, file_path, commit_message=\"Auto-commit from notebook\"):\n",
    "        \"\"\"Push a file to GitHub repository.\"\"\"\n",
    "        import subprocess\n",
    "        import os\n",
    "        \n",
    "        try:\n",
    "            # Get directory of the file\n",
    "            file_dir = os.path.dirname(file_path)\n",
    "            file_name = os.path.basename(file_path)\n",
    "            \n",
    "            # Change to repo directory\n",
    "            os.chdir(file_dir)\n",
    "            \n",
    "            # Git commands\n",
    "            subprocess.run(['git', 'add', file_name], shell=True, check=True)\n",
    "            subprocess.run(['git', 'commit', '-m', commit_message], shell=True, check=True)\n",
    "            subprocess.run(['git', 'push'], shell=True, check=True)\n",
    "            \n",
    "            print(f\"‚úÖ Successfully pushed {file_name} to GitHub\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Git error: {e}\")\n",
    "            return False\n",
    "            \n",
    "            \n",
    "        \n",
    "print(\"‚úÖ GitHubCodeRunner class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a951c8b",
   "metadata": {},
   "source": [
    "### Initialize and Test Github code runner\n",
    "Now let's create an instance and test it interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acb9837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.088427Z",
     "iopub.status.busy": "2025-11-15T17:07:55.088427Z",
     "iopub.status.idle": "2025-11-15T17:07:55.694353Z",
     "shell.execute_reply": "2025-11-15T17:07:55.694353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GitHubCodeRunner initialized!\n",
      "üìÇ Workspace: ./workspace\n",
      "üìÅ Repos directory: ./workspace\\github_repos\n",
      "‚ö†Ô∏è GIT_EMAIL or GIT_NAME not set in .env\n",
      "‚úÖ Created: hello_world.py\n",
      "‚úÖ Created: data_processor.py\n",
      "\n",
      "üìÅ Demo files created in: ./workspace\\github_repos\\demo_scripts\n"
     ]
    }
   ],
   "source": [
    "# Create our runner instance\n",
    "runner = GitHubCodeRunner()\n",
    "\n",
    "# Load git user info from .env\n",
    "import os\n",
    "GIT_EMAIL = os.getenv(\"GIT_EMAIL\")\n",
    "GIT_NAME = os.getenv(\"GIT_NAME\")\n",
    "\n",
    "# Configure git user from environment variables\n",
    "if GIT_EMAIL and GIT_NAME:\n",
    "    !git config --global user.email \"$GIT_EMAIL\"\n",
    "    !git config --global user.name \"$GIT_NAME\"\n",
    "    print(f\"‚úÖ Git user set: {GIT_NAME} <{GIT_EMAIL}>\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GIT_EMAIL or GIT_NAME not set in .env\")\n",
    "\n",
    "# Create demo files\n",
    "demo_path = runner.create_demo_files()\n",
    "print(f\"\\nüìÅ Demo files created in: {demo_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce9d83",
   "metadata": {},
   "source": [
    "\n",
    "### Read Source Data CSV File from Folder\n",
    "Let's read a CSV file from the local 'fidelity' folder and convert it to numpy format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042c025e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.719409Z",
     "iopub.status.busy": "2025-11-15T17:07:55.703607Z",
     "iopub.status.idle": "2025-11-15T17:07:55.752378Z",
     "shell.execute_reply": "2025-11-15T17:07:55.752378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\n",
      "Looking for .env file at: c:\\Users\\patty\\OfficeAgents_new\\OfficeAgents\\analysis_scripts\\.env\n",
      "C:/Users/patty/portfolio_files/Input_Source_files\n",
      "Broker is Fidelity\n",
      "['Portfolio_Positions_Nov-04-2025.csv', 'Portfolio_Positions_Nov-07-2025.csv']\n",
      "‚úÖ Most recent file: Portfolio_Positions_Nov-07-2025.csv\n",
      "   Modified: 2025-11-07 15:06:53\n",
      "Portfolio_Positions_Nov-07-2025.csv\n",
      "C:/Users/patty/portfolio_files/Input_Source_files/Fidelity/Portfolio_Positions_Nov-07-2025.csv\n"
     ]
    }
   ],
   "source": [
    "# Source Data Configuration\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Looking for .env file at:\", os.path.join(os.getcwd(), \".env\"))\n",
    "Source_files_dir = os.getenv(\"Portfolio_source_files_dir\")\n",
    "print(Source_files_dir)\n",
    "BROKER = os.getenv(\"Broker\")\n",
    "print(\"Broker is\", BROKER) \n",
    "# Combine directory paths\n",
    "broker_folder = os.path.join(Source_files_dir, BROKER)\n",
    "\n",
    "# Define filename pattern\n",
    "START_WITH = \"Portfolio_Positions\"\n",
    "EXTENSION = \".csv\"\n",
    "\n",
    "# Find matching files\n",
    "all_files = os.listdir(broker_folder)\n",
    "matching_files = [f for f in all_files \n",
    "                  if f.startswith(START_WITH) and f.endswith(EXTENSION)]\n",
    "print(matching_files)\n",
    "# Get the most recently saved file\n",
    "if matching_files:\n",
    "    file_paths = [os.path.join(broker_folder, f) for f in matching_files]\n",
    "    most_recent_file = max(file_paths, key=os.path.getmtime)\n",
    "    FILENAME = os.path.basename(most_recent_file)\n",
    "    \n",
    "    # Display results\n",
    "    from datetime import datetime\n",
    "    mod_time = os.path.getmtime(most_recent_file)\n",
    "    print(f\"‚úÖ Most recent file: {FILENAME}\")\n",
    "    print(f\"   Modified: {datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(FILENAME)\n",
    "else:\n",
    "    FILENAME = None\n",
    "    print(\"‚ùå No matching files found\")\n",
    "\n",
    "\n",
    "# Combine directory paths\n",
    "from pathlib import Path\n",
    "SOURCE_INPUT = str(Path(broker_folder) / FILENAME).replace('\\\\', '/')\n",
    " \n",
    "print(SOURCE_INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3ceb7",
   "metadata": {},
   "source": [
    "### Classes to Format and Handle Errors on File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350247c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.767240Z",
     "iopub.status.busy": "2025-11-15T17:07:55.767240Z",
     "iopub.status.idle": "2025-11-15T17:07:55.830914Z",
     "shell.execute_reply": "2025-11-15T17:07:55.828350Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_with_newline(*args, **kwargs):\n",
    "    \"\"\"Enhanced print function that ensures proper line breaks\"\"\"\n",
    "    print(*args, **kwargs)\n",
    "    sys.stdout.flush()  # Force output to display immediately\n",
    "\n",
    "\n",
    "def read_csv_to_numpy(fidelity_folder_path, filename=FILENAME):\n",
    "    \"\"\"\n",
    "    Read CSV file from fidelity folder and convert to numpy array\n",
    "    \n",
    "    Args:\n",
    "        fidelity_folder_path (str): Path to the fidelity folder\n",
    "        filename (str, optional): Specific filename, if None will find first .csv file\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Data from CSV file as numpy array\n",
    "        pandas.DataFrame: Original DataFrame for reference\n",
    "    \"\"\"\n",
    "    print(f\"Looking for CSV files in: {fidelity_folder_path}\")\n",
    "    print()\n",
    "\n",
    "    # Check if fidelity folder exists\n",
    "    if not os.path.exists(fidelity_folder_path):\n",
    "        print(f\"‚ùå Folder not found: {fidelity_folder_path}\")\n",
    "        print()\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "    # Find CSV files in the folder\n",
    "    print(\"Scanning folder for CSV files...\")\n",
    "    csv_files = [f for f in os.listdir(fidelity_folder_path) if f.endswith('.csv')]\n",
    "    print()\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"‚ùå No CSV files found in {fidelity_folder_path}\")\n",
    "        print(f\"Files in folder: {os.listdir(fidelity_folder_path)}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Use specified filename or most recently written CSV file\n",
    "    if filename:\n",
    "        if filename in csv_files:\n",
    "            target_file = filename\n",
    "        else:\n",
    "            print(f\"‚ùå Specified file '{filename}' not found\")\n",
    "            print(f\"üìã Available CSV files: {csv_files}\")\n",
    "            return None, None\n",
    "    else:\n",
    "        # Find the most recently written CSV file\n",
    "        csv_files_with_time = []\n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(fidelity_folder_path, csv_file)\n",
    "            mod_time = os.path.getmtime(file_path)\n",
    "            csv_files_with_time.append((csv_file, mod_time))\n",
    "        \n",
    "        # Sort by modification time (most recent first)\n",
    "        csv_files_with_time.sort(key=lambda x: x[1], reverse=True)\n",
    "        target_file = csv_files_with_time[0][0]\n",
    "        \n",
    "        from datetime import datetime\n",
    "        most_recent_time = datetime.fromtimestamp(csv_files_with_time[0][1])\n",
    "        print(f\"Using most recent CSV file: {target_file}\")\n",
    "        print(f\"Last modified: {most_recent_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        if len(csv_files) > 1:\n",
    "            print(f\"Other CSV files found: {len(csv_files)-1} older files\")\n",
    "        print()\n",
    "    \n",
    "    file_path = os.path.join(fidelity_folder_path, target_file)\n",
    "    \n",
    "    try:\n",
    "        # Read CSV file using pandas\n",
    "        print(f\"Reading file: {file_path}\")\n",
    "        print(\"Loading data... (Press Ctrl+C to interrupt)\")\n",
    "        print()\n",
    "        \n",
    "        # Try to read CSV with different common parameters\n",
    "        try:\n",
    "            # First try with standard settings\n",
    "            df = pd.read_csv(file_path)\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Trying different encoding...\")\n",
    "            # Try with different encoding if standard fails\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "            except:\n",
    "                df = pd.read_csv(file_path, encoding='latin1')\n",
    "        except pd.errors.ParserError:\n",
    "            print(\"Trying different separator...\")\n",
    "            # Try with different separator if parsing fails\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=';')  # European format\n",
    "            except:\n",
    "                df = pd.read_csv(file_path, sep='\\t')  # Tab-separated\n",
    "        \n",
    "        print(f\"‚úÖ Successfully loaded CSV file!\")\n",
    "        print(f\"File dimensions: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Remove footer rows starting with \"The data and information in this spreadsheet\"\n",
    "        mask = df.astype(str).apply(lambda x: x.str.lower().str.contains('the data and information in this spreadsheet', na=False)).any(axis=1)\n",
    "        if mask.any():\n",
    "            df = df.iloc[:mask.idxmax()]\n",
    "            print(f\"Removed footer rows, new shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "        # Convert to numpy array\n",
    "        print(\"Converting to numpy array...\")\n",
    "        numpy_array = df.to_numpy()\n",
    "        print()\n",
    "        \n",
    "        # Display variable information prominently\n",
    "        print(f\"DATA LOADED INTO VARIABLES:\")\n",
    "        print(f\"   df_data (pandas DataFrame): {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "        print(f\"   numpy_data (numpy array): {numpy_array.shape[0]:,} rows √ó {numpy_array.shape[1]} columns\")\n",
    "        print(f\"   Memory usage: {numpy_array.nbytes:,} bytes\")\n",
    "        print(f\"   Data type: {numpy_array.dtype}\")\n",
    "        print()\n",
    "        return numpy_array, df\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nOperation interrupted by user\")\n",
    "        print()\n",
    "        return None, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading file: {e}\")\n",
    "        print(f\"Try specifying encoding: pd.read_csv('{file_path}', encoding='utf-8')\")\n",
    "        print()\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1048eb",
   "metadata": {},
   "source": [
    "### Actually Read the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc1c12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.850309Z",
     "iopub.status.busy": "2025-11-15T17:07:55.850309Z",
     "iopub.status.idle": "2025-11-15T17:07:55.932401Z",
     "shell.execute_reply": "2025-11-15T17:07:55.932401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CSV files in: C:/Users/patty/portfolio_files/Input_Source_files\\Fidelity\n",
      "\n",
      "Scanning folder for CSV files...\n",
      "\n",
      "Reading file: C:/Users/patty/portfolio_files/Input_Source_files\\Fidelity\\Portfolio_Positions_Nov-07-2025.csv\n",
      "Loading data... (Press Ctrl+C to interrupt)\n",
      "\n",
      "‚úÖ Successfully loaded CSV file!\n",
      "File dimensions: 61 rows √ó 16 columns\n",
      "Column names: ['Account Number', 'Account Name', 'Symbol', 'Description', 'Quantity', 'Last Price', 'Last Price Change', 'Current Value', \"Today's Gain/Loss Dollar\", \"Today's Gain/Loss Percent\", 'Total Gain/Loss Dollar', 'Total Gain/Loss Percent', 'Percent Of Account', 'Cost Basis Total', 'Average Cost Basis', 'Type']\n",
      "\n",
      "Removed footer rows, new shape: 58 rows √ó 16 columns\n",
      "Converting to numpy array...\n",
      "\n",
      "DATA LOADED INTO VARIABLES:\n",
      "   df_data (pandas DataFrame): 58 rows √ó 16 columns\n",
      "   numpy_data (numpy array): 58 rows √ó 16 columns\n",
      "   Memory usage: 7,424 bytes\n",
      "   Data type: object\n",
      "\n",
      "(58, 16)\n",
      "‚úÖ Successfully converted CSV to numpy array!\n",
      "\n",
      "Data saved in variables:\n",
      "   ‚Ä¢ df_data (pandas DataFrame): 58 rows √ó 16 columns\n",
      "   ‚Ä¢ numpy_data (numpy array): 58 rows √ó 16 columns\n",
      "   ‚Ä¢ File size: 7,424 bytes in memory\n",
      "\n",
      "Basic statistics for numeric columns:\n",
      "   Shape: (58, 16)\n",
      "   Numeric columns: ['Quantity']\n",
      "   Mean values:\n",
      "Quantity    3088.68564\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Removed footer rows, new shape: 58 rows √ó 16 columns\n",
      "Converting to numpy array...\n",
      "\n",
      "DATA LOADED INTO VARIABLES:\n",
      "   df_data (pandas DataFrame): 58 rows √ó 16 columns\n",
      "   numpy_data (numpy array): 58 rows √ó 16 columns\n",
      "   Memory usage: 7,424 bytes\n",
      "   Data type: object\n",
      "\n",
      "(58, 16)\n",
      "‚úÖ Successfully converted CSV to numpy array!\n",
      "\n",
      "Data saved in variables:\n",
      "   ‚Ä¢ df_data (pandas DataFrame): 58 rows √ó 16 columns\n",
      "   ‚Ä¢ numpy_data (numpy array): 58 rows √ó 16 columns\n",
      "   ‚Ä¢ File size: 7,424 bytes in memory\n",
      "\n",
      "Basic statistics for numeric columns:\n",
      "   Shape: (58, 16)\n",
      "   Numeric columns: ['Quantity']\n",
      "   Mean values:\n",
      "Quantity    3088.68564\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file and convert to numpy\n",
    "numpy_data, df_data = read_csv_to_numpy(broker_folder, FILENAME)\n",
    "print(df_data.shape)\n",
    "\n",
    "if numpy_data is not None:\n",
    "    print(f\"‚úÖ Successfully converted CSV to numpy array!\")\n",
    "    print()\n",
    "    print(f\"Data saved in variables:\")\n",
    "    print(f\"   ‚Ä¢ df_data (pandas DataFrame): {df_data.shape[0]:,} rows √ó {df_data.shape[1]} columns\")\n",
    "    print(f\"   ‚Ä¢ numpy_data (numpy array): {numpy_data.shape[0]:,} rows √ó {numpy_data.shape[1]} columns\")\n",
    "    print(f\"   ‚Ä¢ File size: {numpy_data.nbytes:,} bytes in memory\")\n",
    "    print()\n",
    "    \n",
    "    # Show some basic statistics if data is numeric\n",
    "    try:\n",
    "        # Get numeric columns only\n",
    "        numeric_data = df_data.select_dtypes(include=[np.number])\n",
    "        if not numeric_data.empty:\n",
    "            print(f\"Basic statistics for numeric columns:\")\n",
    "            print(f\"   Shape: {numpy_data.shape}\")\n",
    "            print(f\"   Numeric columns: {list(numeric_data.columns)}\")\n",
    "            print(f\"   Mean values:\")\n",
    "            print(numeric_data.mean())\n",
    "            print()\n",
    "            print()  # Add line break\n",
    "        else:\n",
    "            print(\"   (No numeric columns found - use df_data.describe() for text statistics)\")\n",
    "            print()\n",
    "            print()  # Add line break\n",
    "    except Exception as e:\n",
    "        print(f\"   Error calculating statistics: {e}\")\n",
    "        print()\n",
    "        print()  # Add line break\n",
    "\n",
    "else:\n",
    "    print(f\"Fidelity folder not found in common loocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e2f57c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.942357Z",
     "iopub.status.busy": "2025-11-15T17:07:55.942357Z",
     "iopub.status.idle": "2025-11-15T17:07:55.983651Z",
     "shell.execute_reply": "2025-11-15T17:07:55.983651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(58, 16)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58 entries, 0 to 57\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Account Number             58 non-null     object \n",
      " 1   Account Name               58 non-null     object \n",
      " 2   Symbol                     58 non-null     object \n",
      " 3   Description                57 non-null     object \n",
      " 4   Quantity                   50 non-null     float64\n",
      " 5   Last Price                 50 non-null     object \n",
      " 6   Last Price Change          50 non-null     object \n",
      " 7   Current Value              58 non-null     object \n",
      " 8   Today's Gain/Loss Dollar   50 non-null     object \n",
      " 9   Today's Gain/Loss Percent  50 non-null     object \n",
      " 10  Total Gain/Loss Dollar     50 non-null     object \n",
      " 11  Total Gain/Loss Percent    50 non-null     object \n",
      " 12  Percent Of Account         57 non-null     object \n",
      " 13  Cost Basis Total           50 non-null     object \n",
      " 14  Average Cost Basis         50 non-null     object \n",
      " 15  Type                       57 non-null     object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 7.4+ KB\n",
      "None\n",
      "  Account Number        Account Name   Symbol     Description  Quantity  \\\n",
      "0      X44378160  Personal_shortterm  FCASH**   HELD IN FCASH       NaN   \n",
      "1      X44378160  Personal_shortterm     MSFT  MICROSOFT CORP   459.348   \n",
      "\n",
      "  Last Price Last Price Change Current Value Today's Gain/Loss Dollar  \\\n",
      "0        NaN               NaN         $1.64                      NaN   \n",
      "1    $496.82            -$0.28    $228213.27                 -$128.62   \n",
      "\n",
      "  Today's Gain/Loss Percent Total Gain/Loss Dollar Total Gain/Loss Percent  \\\n",
      "0                       NaN                    NaN                     NaN   \n",
      "1                    -0.06%             +$85547.58                 +59.96%   \n",
      "\n",
      "  Percent Of Account Cost Basis Total Average Cost Basis  Type  \n",
      "0              0.00%              NaN                NaN  Cash  \n",
      "1             92.73%       $142665.69            $310.58  Cash  \n",
      "  Account Number        Account Name   Symbol     Description  Quantity  \\\n",
      "0      X44378160  Personal_shortterm  FCASH**   HELD IN FCASH       NaN   \n",
      "1      X44378160  Personal_shortterm     MSFT  MICROSOFT CORP   459.348   \n",
      "\n",
      "  Last Price Last Price Change Current Value Today's Gain/Loss Dollar  \\\n",
      "0        NaN               NaN         $1.64                      NaN   \n",
      "1    $496.82            -$0.28    $228213.27                 -$128.62   \n",
      "\n",
      "  Today's Gain/Loss Percent Total Gain/Loss Dollar Total Gain/Loss Percent  \\\n",
      "0                       NaN                    NaN                     NaN   \n",
      "1                    -0.06%             +$85547.58                 +59.96%   \n",
      "\n",
      "  Percent Of Account Cost Basis Total Average Cost Basis  Type  \n",
      "0              0.00%              NaN                NaN  Cash  \n",
      "1             92.73%       $142665.69            $310.58  Cash  \n"
     ]
    }
   ],
   "source": [
    "# Check existing files.\n",
    "print(type(numpy_data))  # <class 'numpy.ndarray'>\n",
    "print(type(df_data))     # <class 'pandas.DataFrame'>\n",
    "print(numpy_data.shape)  # (rows, columns)\n",
    "print(df_data.info())    # DataFrame info\n",
    "print(df_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd2ab62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:55.990142Z",
     "iopub.status.busy": "2025-11-15T17:07:55.990142Z",
     "iopub.status.idle": "2025-11-15T17:07:56.002561Z",
     "shell.execute_reply": "2025-11-15T17:07:56.002561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Interactive testing area\n",
      "Workspace directory: ./workspace\n",
      "Files in workspace: ['github_repos']\n"
     ]
    }
   ],
   "source": [
    "# Test area - modify as needed\n",
    "print(\"üß™ Interactive testing area\")\n",
    "print(f\"Workspace directory: {runner.workspace_dir}\")\n",
    "print(f\"Files in workspace: {os.listdir(runner.workspace_dir) if os.path.exists(runner.workspace_dir) else 'None'}\")\n",
    "\n",
    "# You can add your own code here to test specific functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a09929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:56.006172Z",
     "iopub.status.busy": "2025-11-15T17:07:56.006172Z",
     "iopub.status.idle": "2025-11-15T17:07:56.072376Z",
     "shell.execute_reply": "2025-11-15T17:07:56.070064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "‚úÖ Asterisk removed\n",
      "‚úÖ Slashes removed\n",
      "‚úÖ NaN's replaced\n",
      "‚úÖ Account Number a String\n",
      "‚úÖ Currency columns converted to numeric format\n",
      "\n",
      "‚úÖ Asterisk removed\n",
      "‚úÖ Slashes removed\n",
      "‚úÖ NaN's replaced\n",
      "‚úÖ Account Number a String\n",
      "‚úÖ Currency columns converted to numeric format\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Clean up the workbook.\n",
    "#print(type(numpy_data))  # <class 'numpy.ndarray'>\n",
    "print(type(df_data))     # <class 'pandas.DataFrame'>\n",
    "\n",
    "# Remove asterisk from Symbol column\n",
    "df_data['Symbol'] = df_data['Symbol'].str.replace('*', '')\n",
    "numpy_data[:, 2] = [str(x).replace('*', '') for x in numpy_data[:, 2]]\n",
    "print(\"‚úÖ Asterisk removed\")\n",
    "\n",
    "# Replace slashes with space\n",
    "df_data.columns = df_data.columns.str.replace('[/\\'\\\"\\\\:]', ' ', regex=True)\n",
    "print(\"‚úÖ Slashes removed\")\n",
    "\n",
    "# Selectively replace NAN's with 0's and 1's Depending on the context\n",
    "df_data['Quantity'].fillna(1, inplace=True)\n",
    "df_data['Last Price'].fillna(1, inplace=True)\n",
    "df_data['Last Price Change'].fillna(0, inplace=True)\n",
    "df_data['Today s Gain Loss Dollar'].fillna(0, inplace=True)\n",
    "df_data['Today s Gain Loss Percent'].fillna(0, inplace=True)\n",
    "df_data['Total Gain Loss Dollar'].fillna(0, inplace=True)\n",
    "df_data['Total Gain Loss Percent'].fillna(0, inplace=True)\n",
    "df_data['Percent Of Account'].fillna(0, inplace=True)\n",
    "df_data['Cost Basis Total'].fillna(0, inplace=True)\n",
    "df_data['Average Cost Basis'].fillna(0, inplace=True)\n",
    "df_data['Description'].fillna('Pending', inplace=True)\n",
    "df_data['Type'].fillna('Pending', inplace=True)\n",
    "print(\"‚úÖ NaN's replaced\")\n",
    "\n",
    "# Convert all account numbers to strings\n",
    "df_data['Account Number'] = df_data['Account Number'].astype(str)\n",
    "print(\"‚úÖ Account Number a String\")\n",
    "\n",
    "# List of columns to format as currency\n",
    "currency_columns = [\n",
    "    'Last Price',\n",
    "    'Last Price Change',\n",
    "    'Today s Gain Loss Dollar',\n",
    "    'Total Gain Loss Dollar',\n",
    "    'Cost Basis Total',\n",
    "    'Average Cost Basis',\n",
    "    'Current Value'\n",
    "]\n",
    "\n",
    "# Convert to numeric\n",
    "for col in currency_columns:\n",
    "    if col in df_data.columns:\n",
    "        # Ensure column is numeric\n",
    "        df_data[col] = pd.to_numeric(df_data[col].str.replace('[$,]', '', regex=True), errors='coerce')\n",
    "\n",
    "\n",
    "print(\"‚úÖ Currency columns converted to numeric format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0aa288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:56.082076Z",
     "iopub.status.busy": "2025-11-15T17:07:56.078412Z",
     "iopub.status.idle": "2025-11-15T17:07:56.138833Z",
     "shell.execute_reply": "2025-11-15T17:07:56.136787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Percentage columns converted to numeric format with 1 decimal place\n",
      "‚úÖ Sorted DataFrame by Total Gain Loss Percent (descending)\n",
      "‚úÖ Columns reordered\n",
      "  Account Number   Account Name Symbol      Description  Current Value  \\\n",
      "0      227285398  ROTH IRA-2017   AMZN   AMAZON.COM INC       57680.76   \n",
      "1      235819796  ROTH IRA-2022   RDDT  REDDIT INC CL A       56233.62   \n",
      "\n",
      "   Percent Of Account  Total Gain Loss Dollar  Total Gain Loss Percent  \\\n",
      "0               0.308                38174.92                    1.957   \n",
      "1               0.476                35149.78                    1.667   \n",
      "\n",
      "   Quantity  Last Price  Last Price Change  Today s Gain Loss Dollar  \\\n",
      "0     236.0      244.41               1.37                    323.32   \n",
      "1     289.0      194.58              10.94                   3161.66   \n",
      "\n",
      "   Today s Gain Loss Percent  Cost Basis Total  Average Cost Basis  Type  \n",
      "0                      0.006          19505.84               82.65  Cash  \n",
      "1                      0.060          21083.84               72.95  Cash  \n",
      "\n",
      "‚úÖ Sorted DataFrame by Total Gain Loss Percent (descending)\n",
      "‚úÖ Columns reordered\n",
      "  Account Number   Account Name Symbol      Description  Current Value  \\\n",
      "0      227285398  ROTH IRA-2017   AMZN   AMAZON.COM INC       57680.76   \n",
      "1      235819796  ROTH IRA-2022   RDDT  REDDIT INC CL A       56233.62   \n",
      "\n",
      "   Percent Of Account  Total Gain Loss Dollar  Total Gain Loss Percent  \\\n",
      "0               0.308                38174.92                    1.957   \n",
      "1               0.476                35149.78                    1.667   \n",
      "\n",
      "   Quantity  Last Price  Last Price Change  Today s Gain Loss Dollar  \\\n",
      "0     236.0      244.41               1.37                    323.32   \n",
      "1     289.0      194.58              10.94                   3161.66   \n",
      "\n",
      "   Today s Gain Loss Percent  Cost Basis Total  Average Cost Basis  Type  \n",
      "0                      0.006          19505.84               82.65  Cash  \n",
      "1                      0.060          21083.84               72.95  Cash  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "percentage_columns = [\n",
    "    'Today s Gain Loss Percent',\n",
    "    'Total Gain Loss Percent',\n",
    "    'Percent Of Account'\n",
    "]\n",
    "\n",
    "# Convert to percentages with 1 decimal point\n",
    "for col in percentage_columns:\n",
    "    if col in df_data.columns:\n",
    "        # Convert to string first\n",
    "        df_data[col] = df_data[col].astype(str)\n",
    "        # Remove any existing % signs\n",
    "        df_data[col] = df_data[col].str.replace('%', '')\n",
    "        # Remove $ and commas if present\n",
    "        df_data[col] = df_data[col].str.replace('[$,]', '', regex=True)\n",
    "        # Replace -- with 0\n",
    "        df_data[col] = df_data[col].str.replace('--', '0')\n",
    "        # Convert to numeric\n",
    "        df_data[col] = pd.to_numeric(df_data[col], errors='coerce')\n",
    "        # Round to 1 decimal place\n",
    "        # Divide by 100 to convert percentage to decimal\n",
    "        df_data[col] = df_data[col] / 100\n",
    "        # Round to 1 decimal place\n",
    "        df_data[col] = df_data[col].round(3)\n",
    "\n",
    "print(\"‚úÖ Percentage columns converted to numeric format with 1 decimal place\")\n",
    "\n",
    "df_data = df_data.sort_values(by='Total Gain Loss Percent', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"‚úÖ Sorted DataFrame by Total Gain Loss Percent (descending)\")\n",
    "\n",
    "# Define the desired column order\n",
    "column_order = [\n",
    "    'Account Number',\n",
    "    'Account Name', \n",
    "    'Symbol',\n",
    "    'Description',\n",
    "    'Current Value',           # Moved here\n",
    "    'Percent Of Account',      # Moved here\n",
    "    'Total Gain Loss Dollar',  # Moved here\n",
    "    'Total Gain Loss Percent', # Moved here\n",
    "    'Quantity',\n",
    "    'Last Price',\n",
    "    'Last Price Change',\n",
    "    'Today s Gain Loss Dollar',\n",
    "    'Today s Gain Loss Percent',\n",
    "    'Cost Basis Total',\n",
    "    'Average Cost Basis',\n",
    "    'Type'\n",
    "]\n",
    "\n",
    "# Reorder columns (only include columns that exist in df_data)\n",
    "existing_columns = [col for col in column_order if col in df_data.columns]\n",
    "df_data = df_data[existing_columns]\n",
    "\n",
    "print(\"‚úÖ Columns reordered\")\n",
    "\n",
    "#Display the first 2 rows of the cleaned DataFrame\n",
    "print(df_data.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68144c",
   "metadata": {},
   "source": [
    "### Refresh Market Prices and Pull Sector ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cac4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:07:56.138833Z",
     "iopub.status.busy": "2025-11-15T17:07:56.138833Z",
     "iopub.status.idle": "2025-11-15T17:08:25.861029Z",
     "shell.execute_reply": "2025-11-15T17:08:25.861029Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‚ö†' (U+26A0) (2165449967.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    ‚ö†Ô∏è Warning: 'Ticker' or 'Price' column missing in result_df. Skipping price update.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '‚ö†' (U+26A0)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "#from docx import Document\n",
    "\n",
    "# Step 1: Load tickers from Excel\n",
    "\n",
    "tickers = df_data['Symbol'].dropna().tolist()\n",
    "print(tickers)\n",
    "\n",
    "# Step 2 & 3: Validate and fetch prices\n",
    "prices = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        data = yf.Ticker(ticker).history(period=\"1d\")\n",
    "        if not data.empty:\n",
    "            current_price = data['Close'].iloc[-1]\n",
    "            prices.append({'Ticker': ticker, 'Price': current_price})\n",
    "        else:\n",
    "            print(f\"No data for ticker: {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "# Step 4: Update df_data with fetched prices\n",
    "result_df = pd.DataFrame(prices)\n",
    "\n",
    "# Create a dictionary for fast lookup: {Ticker: Price}\n",
    "if 'Ticker' in result_df.columns and 'Price' in result_df.columns:\n",
    "    price_lookup = dict(zip(result_df['Ticker'], result_df['Price']))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: 'Ticker' or 'Price' column missing in result_df. Skipping price update.\")\n",
    "    price_lookup = {}\n",
    "\n",
    "# Update df_data['Last Price'] for matching tickers\n",
    "updated_count = 0\n",
    "for idx, row in df_data.iterrows():\n",
    "    ticker = row['Symbol']\n",
    "    if ticker in price_lookup:\n",
    "        df_data.at[idx, 'Last Price'] = price_lookup[ticker]\n",
    "        updated_count += 1\n",
    "\n",
    "print(f\"‚úÖ Updated {updated_count} prices in df_data\")\n",
    "print(f\"Total tickers checked: {len(tickers)}\")\n",
    "print(f\"Prices found: {len(price_lookup)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0d700",
   "metadata": {},
   "source": [
    "### Save cleaned file for later analysis work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b8f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:08:25.870736Z",
     "iopub.status.busy": "2025-11-15T17:08:25.870736Z",
     "iopub.status.idle": "2025-11-15T17:08:26.025147Z",
     "shell.execute_reply": "2025-11-15T17:08:26.025147Z"
    }
   },
   "outputs": [],
   "source": [
    "from openpyxl.formatting.rule import ColorScaleRule\n",
    "output_folder = 'C:/Users/patty/portfolio_files'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "df_data.to_excel(os.path.join(output_folder, 'fidelity_portfolio.xlsx'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c633e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b8a4171",
   "metadata": {},
   "source": [
    "### Push this ipynb up to github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194861f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:08:26.033146Z",
     "iopub.status.busy": "2025-11-15T17:08:26.033146Z",
     "iopub.status.idle": "2025-11-15T17:08:26.283401Z",
     "shell.execute_reply": "2025-11-15T17:08:26.280372Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/patty/OfficeAgents_new/OfficeAgents')\n",
    "\n",
    "\n",
    "import pickleshare\n",
    "\n",
    "# Add the new dated file specifically\n",
    "from datetime import datetime\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "#dated_filename = f'Integrated-portfolio-analysis_{date_str}.ipynb'\n",
    "\n",
    "base_path = 'C:\\\\Users\\\\patty\\\\OfficeAgents_new\\\\OfficeAgents'\n",
    "#dated_file = os.path.join(base_path, dated_filename)\n",
    "\n",
    "# Commit and push all staged files to GitHub\n",
    "\n",
    "os.chdir('C:/Users/patty/OfficeAgents_new/OfficeAgents')\n",
    "\n",
    "# First, add any modified files\n",
    "!git add Integrated-portfolio-analysis*.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5fce29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:08:26.305358Z",
     "iopub.status.busy": "2025-11-15T17:08:26.303262Z",
     "iopub.status.idle": "2025-11-15T17:08:26.332994Z",
     "shell.execute_reply": "2025-11-15T17:08:26.328890Z"
    }
   },
   "outputs": [],
   "source": [
    "search_path = \"C:/\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "files = [\n",
    "    \"C:/Users/patty/miniconda3/ChatGPT_experiment.ipynb\",\n",
    "    \"C:/Users/patty/miniconda3/ChatGPT_experiment_image.ipynb\",\n",
    "    \"C:/Users/patty/miniconda3/.ipynb_checkpoints/ChatGPT_experiment-checkpoint.ipynb\",\n",
    "    \"C:/Users/patty/miniconda3/.ipynb_checkpoints/ChatGPT_experiment_image-checkpoint.ipynb\",\n",
    "    \"C:/Users/patty/notebooks/chatgpt-exp.ipynb\"\n",
    "]\n",
    "\n",
    "# Get modification times for all files that exist\n",
    "file_times = []\n",
    "for file in files:\n",
    "    if os.path.exists(file):\n",
    "        mod_time = os.path.getmtime(file)\n",
    "        file_times.append((file, mod_time))\n",
    "\n",
    "# Sort by modification time (most recent first)\n",
    "file_times.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(\"Files sorted by most recent modification:\\n\")\n",
    "for file, mod_time in file_times:\n",
    "    mod_datetime = datetime.fromtimestamp(mod_time)\n",
    "    print(f\"{mod_datetime.strftime('%Y-%m-%d %H:%M:%S')} - {file}\")\n",
    "\n",
    "# Print the most recent file\n",
    "if file_times:\n",
    "    print(f\"\\n‚úÖ Most recently modified: {file_times[0][0]}\")\n",
    "    print(f\"   Last modified: {datetime.fromtimestamp(file_times[0][1]).strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d603f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:08:26.345885Z",
     "iopub.status.busy": "2025-11-15T17:08:26.345885Z",
     "iopub.status.idle": "2025-11-15T17:08:34.255508Z",
     "shell.execute_reply": "2025-11-15T17:08:34.253483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy current notebook to dated version and push to GitHub\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "current_file = \"Integrated-portfolio-analysis.ipynb\"\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "dated_filename = f'Integrated-portfolio-analysis_{date_str}.ipynb'\n",
    "dated_file = os.path.join('C:\\\\Users\\\\patty\\\\OfficeAgents_new\\\\OfficeAgents', dated_filename)\n",
    "\n",
    "os.chdir('C:/Users/patty/OfficeAgents_new/OfficeAgents')\n",
    "\n",
    "# Create dated copy and sync to GitHub\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "os.chdir('C:/Users/patty/OfficeAgents_new/OfficeAgents')\n",
    "\n",
    "# Create dated filename\n",
    "current_file = \"Integrated-portfolio-analysis.ipynb\"\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "dated_filename = f'Integrated-portfolio-analysis_{date_str}.ipynb'\n",
    "dated_file = os.path.join('C:\\\\Users\\\\patty\\\\OfficeAgents_new\\\\OfficeAgents', dated_filename)\n",
    "\n",
    "# Sync everything to GitHub\n",
    "repo_path = 'C:/Users/patty/OfficeAgents_new/OfficeAgents'\n",
    "runner.sync_and_push(repo_path, \"Add portfolio analysis notebooks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb04fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:08:34.262944Z",
     "iopub.status.busy": "2025-11-15T17:08:34.262944Z",
     "iopub.status.idle": "2025-11-15T17:08:34.274447Z",
     "shell.execute_reply": "2025-11-15T17:08:34.274447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fin  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1b7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
