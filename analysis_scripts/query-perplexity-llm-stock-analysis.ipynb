{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3094c07e",
   "metadata": {},
   "source": [
    "# Stock Analysis Report Generator Using Perplexity\n",
    "\n",
    "<small>\n",
    "\n",
    "#### **Overview**\n",
    "This notebook automatically generates professional stock analysis reports in the style of Brian Belsky (Chief Investment Strategist at BMO Capital Markets) using Perplexity AI's Sonar Pro model. Each report is saved as a formatted Microsoft Word document.6. The prompt used to generate the report\n",
    "Analyst ratings and price targets (when available)\n",
    "\n",
    "#### **Features**\n",
    "- Batch Processing: Processes multiple stocks from a text file3. Key financial metrics table\n",
    "- Smart Skipping: Avoids duplicate API calls by checking for existing reports2. 5-year price performance vs. NASDAQ\n",
    "- Markdown Formatting: Converts AI-generated markdown to professional Word formatting1. Stock ticker and generation date\n",
    "- Comprehensive Analysis: Includes price performance charts, financial metrics, and analyst ratingsEach report includes:\n",
    "- Date Stamping: Automatically timestamps each report## Output Format\n",
    "\n",
    "#### **Requirements**\n",
    "- Perplexity API Key- \n",
    "- Input file: Text file with stock tickers (one per line)\n",
    "- Python 3.7+\n",
    "\n",
    "#### **Output**\n",
    "- Analysis word document for each equity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae5331",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af12a99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:42:44.364831Z",
     "iopub.status.busy": "2025-11-15T16:42:44.364831Z",
     "iopub.status.idle": "2025-11-15T16:43:06.311528Z",
     "shell.execute_reply": "2025-11-15T16:43:06.311528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-docx in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Package installation examples shown above!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check which packages are available and install missing ones\n",
    "# Install from requirements file\n",
    "%pip install -q -r requirements.txt\n",
    "%pip install python-docx\n",
    "print(\"✅ Package installation examples shown above!\")\n",
    "\n",
    "# Import necessary packages\n",
    "import sys\n",
    "import requests\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from time import time\n",
    "np.random.seed(10)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e7554",
   "metadata": {},
   "source": [
    "## Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5442a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.311528Z",
     "iopub.status.busy": "2025-11-15T16:43:06.311528Z",
     "iopub.status.idle": "2025-11-15T16:43:06.328505Z",
     "shell.execute_reply": "2025-11-15T16:43:06.328505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/patty/portfolio_files/Individual_stock_analysis\n",
      "C:/Users/patty/portfolio_files/Portfolio_analysis\n",
      "['AMZN', 'RDDT', 'WBD', 'MSFT', 'VWICX', 'CEG', 'JPM', 'LLY', 'UBER', 'BBJP', 'VNM', 'PPH', 'NOW', 'VPU', 'AGNC', 'GOOG', 'IBB', 'JXI', 'GS', 'PAA', 'HESM', 'GLD', 'WES', 'XAR', 'CORE', 'QQQ', 'MPLX', 'BRKB', 'VPU', 'TLT', 'ET', 'IBIT', 'BA', 'RNMBY', 'ABNB', 'SETM', 'TWO', 'VFFSX', 'FIVLX']\n",
      "give me a Brian Belsky style stock analysis for this actual stock market stock in a 3 page or less format. \n",
      "Insert a chart at the top with trailing 5 year stock price performance of this stock vs. the \n",
      "Nasdaq as well as a table of all the key financial metrics for this stock. Make certain all of the facts are correct.  \n",
      "If available, please add analyst ratings and price targets for this stock or mutual fund.\n",
      " \n",
      "\"Taking all of these equities and other types of funds a comprehensive portfolio analysis covering the following equity and fund tickers:\n",
      "\n",
      "\n",
      "Sort the table by industry category. For each ticker, include columns for:\n",
      "\n",
      "    Investment category/industry\n",
      "\n",
      "    PE ratio (TTM)\n",
      "\n",
      "    ROE (%)\n",
      "\n",
      "    Dividend yield (%)\n",
      "\n",
      "    Most recent revenue figure (USD billions)\n",
      "\n",
      "    Beta\n",
      "\n",
      "    Analyst recommendation\n",
      "\n",
      "\n",
      "If available, also note whether the ticker is an ETF or mutual fund or other type of asset. Use ETF averages or top constituent weights when individual metrics are unavailable. Format the result as a markdown table for easy review.\"\n",
      " \n",
      "\"Check these tickers listed. For each, provide the number of analyst upgrades and downgrades in the last week, and the current consensus analyst rating. List results by ticker.\"\n"
     ]
    }
   ],
   "source": [
    "### Variable informational detail\n",
    "# **MAX_TOKENS**: `2000` - Maximum length of generated response\n",
    "# **INPUT_DIR**: Directory containing the equity list file- **TEMPERATURE**: `0` - Deterministic output for consistent, factual analysis\n",
    "# **OUTPUT_DIR**: Directory where generated reports will be saved- **MODEL**: `sonar-pro` - Perplexity's most advanced model with real-time web access and current financial data\n",
    "# **EQUITY_LIST_FILE**: Text file with stock tickers (one per line)\n",
    "# **Model Settings: Specific model to be invoked, 0 temperature to eliminate creativity and limit the number of tokens for the query.\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "# Input/Output Configuration\n",
    "INPUT_DIR = os.getenv(\"Input_dir\")\n",
    "OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS = os.getenv(\"Output_dir_individual_equities\")\n",
    "print(OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS)\n",
    "OUTPUT_DIR_PORTFOLIO_ANALYSIS = os.getenv(\"Output_dir_portfolio\")\n",
    "print(OUTPUT_DIR_PORTFOLIO_ANALYSIS)\n",
    "PROMPT_DIR = os.getenv(\"Prompt_dir\")\n",
    "EQUITY_LIST_FILE = os.getenv(\"EQUITY_LIST_FILE\")\n",
    "PROMPT_INDIVIDUAL_EQUITY_ANALYSIS = os.getenv(\"PROMPT_INDIVIDUAL_EQUITY_FILE\")\n",
    "PROMPT_PORTFOLIO_ANALYSIS = os.getenv(\"PROMPT_PORTFOLIO_FILE\")\n",
    "PROMPT_RATINGS_CHANGE=os.getenv(\"PROMPT_RATINGS_CHANGE_FILE\")\n",
    "\n",
    "# Read stock list from file\n",
    "with open(EQUITY_LIST_FILE, 'r') as f:\n",
    "    EQUITY_LIST = [line.strip() for line in f if line.strip()]\n",
    "print(EQUITY_LIST)\n",
    "\n",
    "# Read prompt template from file\n",
    "with open(PROMPT_INDIVIDUAL_EQUITY_ANALYSIS, 'r') as f:\n",
    "    PROMPT_TEMPLATE = f.read().strip()\n",
    "print(PROMPT_TEMPLATE)\n",
    "\n",
    "# Read prompt template from file\n",
    "with open(PROMPT_PORTFOLIO_ANALYSIS, 'r') as f:\n",
    "    PROMPT_PORTFOLIO_TEMPLATE = f.read().strip()\n",
    "print(\" \")\n",
    "print(PROMPT_PORTFOLIO_TEMPLATE)\n",
    "\n",
    "# Read prompt template from file\n",
    "with open(PROMPT_RATINGS_CHANGE, 'r') as f:\n",
    "    PROMPT_RATINGS_CHANGE_TEMPLATE = f.read().strip()\n",
    "print(\" \")\n",
    "print(PROMPT_RATINGS_CHANGE_TEMPLATE)\n",
    "\n",
    "# Model Configuration\n",
    "MODEL = \"sonar-pro\" \n",
    "TEMPERATURE = 0\n",
    "MAX_TOKENS = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be69d6",
   "metadata": {},
   "source": [
    "## Define Class to Call Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72547de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.332162Z",
     "iopub.status.busy": "2025-11-15T16:43:06.332162Z",
     "iopub.status.idle": "2025-11-15T16:43:06.338931Z",
     "shell.execute_reply": "2025-11-15T16:43:06.338931Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class PerplexityClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://api.perplexity.ai\"\n",
    "        )\n",
    "\n",
    "    def chat(self, message, model=MODEL):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": message}]\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf5677",
   "metadata": {},
   "source": [
    "## Define Classes to Format the Output in a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "860289cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.339940Z",
     "iopub.status.busy": "2025-11-15T16:43:06.339940Z",
     "iopub.status.idle": "2025-11-15T16:43:06.359281Z",
     "shell.execute_reply": "2025-11-15T16:43:06.359281Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_markdown_to_word(doc, markdown_text):\n",
    "    \"\"\"Convert markdown text to formatted Word document content\"\"\"\n",
    "    lines = markdown_text.split('\\n')\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        \n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Headers (# ## ###)\n",
    "        if line.startswith('#'):\n",
    "            level = len(line) - len(line.lstrip('#'))\n",
    "            text = line.lstrip('#').strip()\n",
    "            doc.add_heading(text, level=min(level, 9))\n",
    "        \n",
    "        # Tables (|...)\n",
    "        elif '|' in line and i + 1 < len(lines) and '|' in lines[i + 1]:\n",
    "            # Parse table\n",
    "            table_lines = [line]\n",
    "            i += 1\n",
    "            # Skip separator line\n",
    "            if '---' in lines[i] or ':-:' in lines[i]:\n",
    "                i += 1\n",
    "            # Get table rows\n",
    "            while i < len(lines) and '|' in lines[i]:\n",
    "                table_lines.append(lines[i])\n",
    "                i += 1\n",
    "            \n",
    "            # Create table\n",
    "            headers = [cell.strip() for cell in table_lines[0].split('|') if cell.strip()]\n",
    "            num_cols = len(headers)\n",
    "            num_rows = len(table_lines)\n",
    "            \n",
    "            table = doc.add_table(rows=num_rows, cols=num_cols)\n",
    "            table.style = 'Light Grid Accent 1'\n",
    "            \n",
    "            # Add headers\n",
    "            for j, header in enumerate(headers):\n",
    "                cell = table.rows[0].cells[j]\n",
    "                cell.text = header\n",
    "                cell.paragraphs[0].runs[0].bold = True\n",
    "            \n",
    "            # Add data rows\n",
    "            for row_idx in range(1, len(table_lines)):\n",
    "                cells = [cell.strip() for cell in table_lines[row_idx].split('|') if cell.strip()]\n",
    "                for col_idx, cell_text in enumerate(cells):\n",
    "                    if col_idx < num_cols:\n",
    "                        table.rows[row_idx].cells[col_idx].text = cell_text\n",
    "            \n",
    "            doc.add_paragraph()  # Add space after table\n",
    "            continue\n",
    "        \n",
    "        # Bullet points (- or *)\n",
    "        elif line.strip().startswith(('- ', '* ', '• ')):\n",
    "            text = line.strip()[2:].strip()\n",
    "            # Handle bold/italic in bullet points\n",
    "            p = doc.add_paragraph(style='List Bullet')\n",
    "            add_formatted_text(p, text)\n",
    "        \n",
    "        # Numbered lists (1. 2. etc)\n",
    "        elif re.match(r'^\\d+\\.\\s', line.strip()):\n",
    "            text = re.sub(r'^\\d+\\.\\s', '', line.strip())\n",
    "            p = doc.add_paragraph(style='List Number')\n",
    "            add_formatted_text(p, text)\n",
    "        \n",
    "        # Bold text with **\n",
    "        elif '**' in line or '__' in line:\n",
    "            p = doc.add_paragraph()\n",
    "            add_formatted_text(p, line)\n",
    "        \n",
    "        # Regular paragraph\n",
    "        else:\n",
    "            p = doc.add_paragraph()\n",
    "            add_formatted_text(p, line)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "def add_formatted_text(paragraph, text):\n",
    "    \"\"\"Add text with bold/italic markdown formatting to a paragraph\"\"\"\n",
    "    # Handle **bold** and __bold__\n",
    "    parts = re.split(r'(\\*\\*.*?\\*\\*|__.*?__|`.*?`)', text)\n",
    "    \n",
    "    for part in parts:\n",
    "        if not part:\n",
    "            continue\n",
    "        \n",
    "        if part.startswith('**') and part.endswith('**'):\n",
    "            run = paragraph.add_run(part[2:-2])\n",
    "            run.bold = True\n",
    "        elif part.startswith('__') and part.endswith('__'):\n",
    "            run = paragraph.add_run(part[2:-2])\n",
    "            run.bold = True\n",
    "        elif part.startswith('`') and part.endswith('`'):\n",
    "            run = paragraph.add_run(part[1:-1])\n",
    "            run.font.name = 'Courier New'\n",
    "        else:\n",
    "            paragraph.add_run(part)\n",
    "\n",
    "\n",
    "def sort_markdown_table_by_industry(markdown_text):\n",
    "    lines = markdown_text.split('\\n')\n",
    "    table_start = None\n",
    "    table_end = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and table_start is None:\n",
    "            table_start = i\n",
    "        elif table_start is not None and ('|' not in line or not line.strip()):\n",
    "            table_end = i\n",
    "            break\n",
    "    if table_start is None or table_end is None:\n",
    "        return markdown_text  # No table found\n",
    "\n",
    "    header = lines[table_start]\n",
    "    separator = lines[table_start + 1]\n",
    "    rows = lines[table_start + 2:table_end]\n",
    "    # Find the index of the Industry/Category column\n",
    "    columns = [col.strip().lower() for col in header.split('|')]\n",
    "    try:\n",
    "        industry_idx = columns.index('industry')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            industry_idx = columns.index('category')\n",
    "        except ValueError:\n",
    "            return markdown_text  # No industry/category column\n",
    "\n",
    "    # Sort rows by industry/category\n",
    "    def get_industry(row):\n",
    "        cells = [cell.strip() for cell in row.split('|')]\n",
    "        return cells[industry_idx] if industry_idx < len(cells) else ''\n",
    "    rows_sorted = sorted(rows, key=get_industry)\n",
    "\n",
    "    # Rebuild the markdown\n",
    "    sorted_table = [header, separator] + rows_sorted\n",
    "    lines = lines[:table_start] + sorted_table + lines[table_end:]\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2944b10",
   "metadata": {},
   "source": [
    "## Generate Analysis for Each Stock in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f20522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.364029Z",
     "iopub.status.busy": "2025-11-15T16:43:06.364029Z",
     "iopub.status.idle": "2025-11-15T16:43:06.784506Z",
     "shell.execute_reply": "2025-11-15T16:43:06.784506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AMZN\n",
      "⏭️  Skipping AMZN - report already exists for 2025-11-16\n",
      "Processing: RDDT\n",
      "⏭️  Skipping RDDT - report already exists for 2025-11-16\n",
      "Processing: WBD\n",
      "⏭️  Skipping WBD - report already exists for 2025-11-16\n",
      "Processing: MSFT\n",
      "⏭️  Skipping MSFT - report already exists for 2025-11-16\n",
      "Processing: VWICX\n",
      "⏭️  Skipping VWICX - report already exists for 2025-11-16\n",
      "Processing: CEG\n",
      "⏭️  Skipping CEG - report already exists for 2025-11-16\n",
      "Processing: JPM\n",
      "⏭️  Skipping JPM - report already exists for 2025-11-16\n",
      "Processing: LLY\n",
      "⏭️  Skipping LLY - report already exists for 2025-11-16\n",
      "Processing: UBER\n",
      "⏭️  Skipping UBER - report already exists for 2025-11-16\n",
      "Processing: BBJP\n",
      "⏭️  Skipping BBJP - report already exists for 2025-11-16\n",
      "Processing: VNM\n",
      "⏭️  Skipping VNM - report already exists for 2025-11-16\n",
      "Processing: PPH\n",
      "⏭️  Skipping PPH - report already exists for 2025-11-16\n",
      "Processing: NOW\n",
      "⏭️  Skipping NOW - report already exists for 2025-11-16\n",
      "Processing: VPU\n",
      "⏭️  Skipping VPU - report already exists for 2025-11-16\n",
      "Processing: AGNC\n",
      "⏭️  Skipping AGNC - report already exists for 2025-11-16\n",
      "Processing: GOOG\n",
      "⏭️  Skipping GOOG - report already exists for 2025-11-16\n",
      "Processing: IBB\n",
      "⏭️  Skipping IBB - report already exists for 2025-11-16\n",
      "Processing: JXI\n",
      "⏭️  Skipping JXI - report already exists for 2025-11-16\n",
      "Processing: GS\n",
      "⏭️  Skipping GS - report already exists for 2025-11-16\n",
      "Processing: PAA\n",
      "⏭️  Skipping PAA - report already exists for 2025-11-16\n",
      "Processing: HESM\n",
      "⏭️  Skipping HESM - report already exists for 2025-11-16\n",
      "Processing: GLD\n",
      "⏭️  Skipping GLD - report already exists for 2025-11-16\n",
      "Processing: WES\n",
      "⏭️  Skipping WES - report already exists for 2025-11-16\n",
      "Processing: XAR\n",
      "⏭️  Skipping XAR - report already exists for 2025-11-16\n",
      "Processing: CORE\n",
      "⏭️  Skipping CORE - report already exists for 2025-11-16\n",
      "Processing: QQQ\n",
      "⏭️  Skipping QQQ - report already exists for 2025-11-16\n",
      "Processing: MPLX\n",
      "⏭️  Skipping MPLX - report already exists for 2025-11-16\n",
      "Processing: BRKB\n",
      "⏭️  Skipping BRKB - report already exists for 2025-11-16\n",
      "Processing: VPU\n",
      "⏭️  Skipping VPU - report already exists for 2025-11-16\n",
      "Processing: TLT\n",
      "⏭️  Skipping TLT - report already exists for 2025-11-16\n",
      "Processing: ET\n",
      "⏭️  Skipping ET - report already exists for 2025-11-16\n",
      "Processing: IBIT\n",
      "⏭️  Skipping IBIT - report already exists for 2025-11-16\n",
      "Processing: BA\n",
      "⏭️  Skipping BA - report already exists for 2025-11-16\n",
      "Processing: RNMBY\n",
      "⏭️  Skipping RNMBY - report already exists for 2025-11-16\n",
      "Processing: ABNB\n",
      "⏭️  Skipping ABNB - report already exists for 2025-11-16\n",
      "Processing: SETM\n",
      "⏭️  Skipping SETM - report already exists for 2025-11-16\n",
      "Processing: TWO\n",
      "⏭️  Skipping TWO - report already exists for 2025-11-16\n",
      "Processing: VFFSX\n",
      "⏭️  Skipping VFFSX - report already exists for 2025-11-16\n",
      "Processing: FIVLX\n",
      "⏭️  Skipping FIVLX - report already exists for 2025-11-16\n",
      "0\n",
      "\n",
      "============================================================\n",
      "✅ Completed processing 39 equities\n",
      "Reports saved to: C:/Users/patty/portfolio_files/Individual_stock_analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS, exist_ok=True)  \n",
    "\n",
    "# Initialize\n",
    "#  Perplexity client\n",
    "client = PerplexityClient(api_key=API_KEY)\n",
    "counter = 0\n",
    "# Process each equity\n",
    "for equity in EQUITY_LIST:\n",
    " \n",
    "    # Construct prompt with equity ticker and template from file\n",
    "    prompt = f\"For the equity {equity} {PROMPT_TEMPLATE}\"\n",
    "    print(f\"Processing: {equity}\")\n",
    "    \n",
    "    # Check if report already exists for today\n",
    "    date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    output_filename = f\"Equity Report - {equity} {date_str}.docx\"\n",
    "    output_path = os.path.join(OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS, output_filename)\n",
    " \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"⏭️  Skipping {equity} - report already exists for {date_str}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Query the LLM\n",
    "        print(f\"Querying Perplexity API for {equity}...\")\n",
    "        \n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        \n",
    "        # Create Word document\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"Market Outlook Report - {equity}\", 0)\n",
    "        doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "        doc.add_paragraph()\n",
    "        \n",
    "        # Convert markdown to Word formatting\n",
    "        add_markdown_to_word(doc, generated_text)\n",
    "        \n",
    "        # Add prompt at the end\n",
    "        doc.add_paragraph()\n",
    "        doc.add_heading(\"Prompt Used:\", level=2)\n",
    "        doc.add_paragraph(prompt)\n",
    "        \n",
    "        # Save the document\n",
    "        doc.save(output_path)\n",
    "        print(f\"✅ Saved: {output_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {equity}: {e}\")\n",
    "        continue\n",
    "print(counter) \n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✅ Completed processing {len(EQUITY_LIST)} equities\")\n",
    "print(f\"Reports saved to: {OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee5794",
   "metadata": {},
   "source": [
    "## Generate Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91aa2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing portfolio for: AMZN, RDDT, WBD, MSFT, VWICX, CEG, JPM, LLY, UBER, BBJP, VNM, PPH, NOW, VPU, AGNC, GOOG, IBB, JXI, GS, PAA, HESM, GLD, WES, XAR, CORE, QQQ, MPLX, BRKB, VPU, TLT, ET, IBIT, BA, RNMBY, ABNB, SETM, TWO, VFFSX, FIVLX\n",
      "Querying Perplexity API for portfolio...\n",
      "✅ Saved: Portfolio Report 2025-11-16.docx\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from docx.shared import Pt\n",
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_PORTFOLIO_ANALYSIS, exist_ok=True)\n",
    "\n",
    "# Initialize Perplexity client\n",
    "client = PerplexityClient(api_key=API_KEY)\n",
    "\n",
    "# Generate a single prompt for the entire EQUITY_LIST using PROMPT_PORTFOLIO_ANALYSIS\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "output_filename = f\"Portfolio Report {date_str}.docx\"\n",
    "output_path = os.path.join(OUTPUT_DIR_PORTFOLIO_ANALYSIS, output_filename)\n",
    "\n",
    "# Combine all equities into a single string (comma separated, or as a list)\n",
    "equity_str = ', '.join(EQUITY_LIST)\n",
    "\n",
    "# Read the portfolio prompt template from file (already done above)\n",
    "# with open(PROMPT_PORTFOLIO_ANALYSIS, 'r') as f:\n",
    "#     PROMPT_PORTFOLIO_TEMPLATE = f.read().strip()\n",
    "\n",
    "# Construct the prompt for the entire list\n",
    "prompt = f\"For the equities {equity_str} {PROMPT_PORTFOLIO_TEMPLATE}\"\n",
    "print(f\"Processing portfolio for: {equity_str}\")\n",
    "\n",
    "# Check if report already exists for today\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"⏭️  Skipping portfolio - report already exists for {date_str}\")\n",
    "else:\n",
    "    try:\n",
    "        # Query the LLM\n",
    "        print(f\"Querying Perplexity API for portfolio...\")\n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "\n",
    "        # Sort the markdown table by Industry/Category\n",
    "        sorted_markdown = sort_markdown_table_by_industry(generated_text)\n",
    "\n",
    "        # Create Word document\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"Market Outlook Portfolio Report\", 0)\n",
    "        doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "        doc.add_paragraph()\n",
    "\n",
    "        # Convert markdown to Word formatting\n",
    "        add_markdown_to_word(doc, sorted_markdown)\n",
    "\n",
    "        # Apply formatting to the last table (smaller font, no bold, remove asterisks)\n",
    "        if doc.tables:\n",
    "            table = doc.tables[-1]\n",
    "            for row in table.rows:\n",
    "                for cell in row.cells:\n",
    "                    for paragraph in cell.paragraphs:\n",
    "                        for run in paragraph.runs:\n",
    "                            run.font.size = Pt(8)\n",
    "                            run.bold = False\n",
    "                            run.text = run.text.replace('*', '')\n",
    "\n",
    "        # Add prompt at the end\n",
    "        doc.add_paragraph()\n",
    "        doc.add_heading(\"Prompt Used:\", level=2)\n",
    "        doc.add_paragraph(prompt)\n",
    "\n",
    "        # Save the document\n",
    "        doc.save(output_path)\n",
    "        print(f\"✅ Saved: {output_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing portfolio: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f8e64",
   "metadata": {},
   "source": [
    "## Generate Ratings Change Report and Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Ratings Change Report for All Equities and Save to Single Document\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_PORTFOLIO_ANALYSIS, exist_ok=True)\n",
    "\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "output_filename = f\"Ratings Change Report {date_str}.docx\"\n",
    "output_path = os.path.join(OUTPUT_DIR_PORTFOLIO_ANALYSIS, output_filename)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Ratings Change Report\", 0)\n",
    "doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "doc.add_paragraph()\n",
    "\n",
    "for equity in EQUITY_LIST:\n",
    "    prompt = f\"For the equity {equity} {PROMPT_RATINGS_CHANGE_TEMPLATE}\"\n",
    "    doc.add_heading(f\"{equity}\", level=1)\n",
    "    try:\n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "        add_markdown_to_word(doc, generated_text)\n",
    "    except Exception as e:\n",
    "        doc.add_paragraph(f\"❌ Error processing {equity}: {e}\")\n",
    "    doc.add_paragraph()  # Space between equities\n",
    "\n",
    "# Add prompt template at the end for reference\n",
    "doc.add_heading(\"Prompt Template Used:\", level=2)\n",
    "doc.add_paragraph(PROMPT_RATINGS_CHANGE_TEMPLATE)\n",
    "\n",
    "doc.save(output_path)\n",
    "print(f\"✅ Saved: {output_filename} in {OUTPUT_DIR_PORTFOLIO_ANALYSIS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
