{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3094c07e",
   "metadata": {},
   "source": [
    "# Stock Analysis Report Generator Using Perplexity\n",
    "\n",
    "<small>\n",
    "\n",
    "#### **Overview**\n",
    "This notebook automatically generates professional stock analysis reports in the style of Brian Belsky (Chief Investment Strategist at BMO Capital Markets) using Perplexity AI's Sonar Pro model. Each report is saved as a formatted Microsoft Word document.6. The prompt used to generate the report\n",
    "Analyst ratings and price targets (when available)\n",
    "\n",
    "#### **Features**\n",
    "- Batch Processing: Processes multiple stocks from a text file3. Key financial metrics table\n",
    "- Smart Skipping: Avoids duplicate API calls by checking for existing reports2. 5-year price performance vs. NASDAQ\n",
    "- Markdown Formatting: Converts AI-generated markdown to professional Word formatting1. Stock ticker and generation date\n",
    "- Comprehensive Analysis: Includes price performance charts, financial metrics, and analyst ratingsEach report includes:\n",
    "- Date Stamping: Automatically timestamps each report## Output Format\n",
    "\n",
    "#### **Requirements**\n",
    "- Perplexity API Key- \n",
    "- Input file: Text file with stock tickers (one per line)\n",
    "- Python 3.7+\n",
    "\n",
    "#### **Output**\n",
    "- Analysis word document for each equity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae5331",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af12a99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:42:44.364831Z",
     "iopub.status.busy": "2025-11-15T16:42:44.364831Z",
     "iopub.status.idle": "2025-11-15T16:43:06.311528Z",
     "shell.execute_reply": "2025-11-15T16:43:06.311528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-docx in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\patty\\miniconda3\\envs\\lerobot\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Package installation examples shown above!\n"
     ]
    }
   ],
   "source": [
    "# Check which packages are available and install missing ones\n",
    "# Install from requirements file\n",
    "%pip install -q -r requirements.txt\n",
    "%pip install python-docx\n",
    "print(\"✅ Package installation examples shown above!\")\n",
    "\n",
    "# Import necessary packages\n",
    "import sys\n",
    "import requests\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from time import time\n",
    "np.random.seed(10)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e7554",
   "metadata": {},
   "source": [
    "## Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5442a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.311528Z",
     "iopub.status.busy": "2025-11-15T16:43:06.311528Z",
     "iopub.status.idle": "2025-11-15T16:43:06.328505Z",
     "shell.execute_reply": "2025-11-15T16:43:06.328505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me a Brian Belsky style stock analysis for this actual stock market stock in a 3 page or less format. \n",
      "Insert a chart at the top with trailing 5 year stock price performance of this stock vs. the \n",
      "Nasdaq as well as a table of all the key financial metrics for this stock including the following key financial metrics\n",
      "\n",
      "    Investment category/industry\n",
      "\n",
      "    PE ratio (TTM)\n",
      "\n",
      "    ROE (%)\n",
      "\n",
      "    Dividend yield (%)\n",
      "\n",
      "    Most recent revenue figure (USD billions)\n",
      "\n",
      "    Beta\n",
      "\n",
      "    Analyst recommendation\n",
      " Make certain all of the facts are correct.  \n",
      "\n",
      "If available, please add analyst ratings and price targets for this stock or mutual fund.\n",
      " \n",
      "\"Taking all of these equities and other types of funds a comprehensive portfolio analysis covering the following equity and fund tickers:\n",
      "\n",
      "\n",
      "Sort the table by industry category. For each ticker, include columns for:\n",
      "\n",
      "    Investment category/industry\n",
      "\n",
      "    PE ratio (TTM)\n",
      "\n",
      "    ROE (%)\n",
      "\n",
      "    Dividend yield (%)\n",
      "\n",
      "    Most recent revenue figure (USD billions)\n",
      "\n",
      "    Beta\n",
      "\n",
      "    Analyst recommendation\n",
      "\n",
      "\n",
      "If available, also note whether the ticker is an ETF or mutual fund or other type of asset. Use ETF averages or top constituent weights when individual metrics are unavailable. Format the result as a markdown table for easy review.\"\n",
      " \n",
      "\"Check these tickers listed. For each, provide the number of analyst upgrades and downgrades in the last week, and the current consensus analyst rating as well as a synopsis of the consensus analysis. List results by ticker.\"\n",
      "PattyRyan patty.ryan@outlook.com\n"
     ]
    }
   ],
   "source": [
    "### Variable informational detail\n",
    "# **MAX_TOKENS**: `2000` - Maximum length of generated response\n",
    "# **INPUT_DIR**: Directory containing the equity list file- **TEMPERATURE**: `0` - Deterministic output for consistent, factual analysis\n",
    "# **OUTPUT_DIR**: Directory where generated reports will be saved- **MODEL**: `sonar-pro` - Perplexity's most advanced model with real-time web access and current financial data\n",
    "# **EQUITY_LIST_FILE**: Text file with stock tickers (one per line)\n",
    "# **Model Settings: Specific model to be invoked, 0 temperature to eliminate creativity and limit the number of tokens for the query.\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "# Input/Output Configuration\n",
    "INPUT_DIR = os.getenv(\"Input_dir\")\n",
    "OUTPUT_DIR_SEC_FILINGS = os.getenv(\"Output_dir_sec_filings\")\n",
    "OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS = os.getenv(\"Output_dir_individual_equities\")\n",
    "OUTPUT_DIR_PORTFOLIO_ANALYSIS = os.getenv(\"Output_dir_portfolio\")\n",
    "PROMPT_DIR = os.getenv(\"Prompt_dir\")\n",
    "EQUITY_LIST_FILE = os.getenv(\"EQUITY_LIST_FILE\")\n",
    "PROMPT_INDIVIDUAL_EQUITY_ANALYSIS = os.getenv(\"PROMPT_INDIVIDUAL_EQUITY_FILE\")\n",
    "PROMPT_PORTFOLIO_ANALYSIS = os.getenv(\"PROMPT_PORTFOLIO_FILE\")\n",
    "PROMPT_RATINGS_CHANGE=os.getenv(\"PROMPT_RATINGS_CHANGE_FILE\")\n",
    "\n",
    "# Read stock list from file\n",
    "with open(EQUITY_LIST_FILE, 'r') as f:\n",
    "    EQUITY_LIST = [line.strip() for line in f if line.strip()]\n",
    "# print small selection of equities from list to verify \n",
    "#print(EQUITY_LIST)  # Print equities for verification\n",
    "  \n",
    "# Read prompt template from file\n",
    "with open(PROMPT_INDIVIDUAL_EQUITY_ANALYSIS, 'r') as f:\n",
    "    PROMPT_TEMPLATE = f.read().strip()\n",
    "print(PROMPT_TEMPLATE)\n",
    "\n",
    "# Read prompt template from file\n",
    "with open(PROMPT_PORTFOLIO_ANALYSIS, 'r') as f:\n",
    "    PROMPT_PORTFOLIO_TEMPLATE = f.read().strip()\n",
    "print(\" \")\n",
    "print(PROMPT_PORTFOLIO_TEMPLATE)\n",
    "\n",
    "# Read prompt template from file\n",
    "with open(PROMPT_RATINGS_CHANGE, 'r') as f:\n",
    "    PROMPT_RATINGS_CHANGE_TEMPLATE = f.read().strip()\n",
    "print(\" \")\n",
    "print(PROMPT_RATINGS_CHANGE_TEMPLATE)\n",
    "\n",
    "# Model Configuration\n",
    "MODEL = \"sonar-pro\" \n",
    "TEMPERATURE = 0\n",
    "MAX_TOKENS = 2000\n",
    "\n",
    "# SEC code header\n",
    "SEC_HEADER =os.getenv(\"User_Agent\")  \n",
    "print(SEC_HEADER)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be69d6",
   "metadata": {},
   "source": [
    "## Define Class to Call Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72547de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.332162Z",
     "iopub.status.busy": "2025-11-15T16:43:06.332162Z",
     "iopub.status.idle": "2025-11-15T16:43:06.338931Z",
     "shell.execute_reply": "2025-11-15T16:43:06.338931Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class PerplexityClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://api.perplexity.ai\"\n",
    "        )\n",
    "\n",
    "    def chat(self, message, model=MODEL):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": message}]\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13d27b",
   "metadata": {},
   "source": [
    "## Define Functions to Retrieve SEC Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9af6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch SEC CIK code for a given ticker symbol\n",
    "def get_cik(ticker):\n",
    "    \"\"\"\n",
    "    Retrieve the CIK (Central Index Key) for a given stock ticker from the SEC database.\n",
    "    Returns the CIK as a zero-padded string if found, otherwise None.\n",
    "    \"\"\"\n",
    "    url = \"https://www.sec.gov/files/company_tickers_exchange.json\"\n",
    "    headers = {\"User-Agent\": SEC_HEADER}\n",
    "    print(\"Fetching CIK for ticker:\", ticker)\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Failed to fetch CIK data. Status code: {resp.status_code}\")\n",
    "        return None\n",
    "    try:\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(\"Response text:\", resp.text[:200])\n",
    "        return None\n",
    "    # SEC JSON structure: {'fields': [...], 'data': [[...], ...]}\n",
    "    if isinstance(data, dict) and \"fields\" in data and \"data\" in data:\n",
    "        fields = data[\"fields\"]\n",
    "        data_list = data[\"data\"]\n",
    "        # Find the index for 'ticker' and for the CIK field (usually 'cik' or 'cik_str')\n",
    "        ticker_idx = next((i for i, f in enumerate(fields) if f.lower() == \"ticker\"), None)\n",
    "        cik_idx = next((i for i, f in enumerate(fields) if \"cik\" in f.lower()), None)\n",
    "        if ticker_idx is None or cik_idx is None:\n",
    "            print(\"Could not find required fields in SEC data.\")\n",
    "            return None\n",
    "        for entry in data_list:\n",
    "            if entry[ticker_idx].upper() == ticker.upper():\n",
    "                return str(entry[cik_idx]).zfill(10)\n",
    "        print(f\"Ticker {ticker} not found in SEC database.\")\n",
    "        return None\n",
    "    print(\"Unexpected SEC JSON structure.\")\n",
    "    return None\n",
    "\n",
    "# Fetch recent SEC filings for a given CIK\n",
    "def get_sec_filings(cik, forms=[\"10-K\", \"10-Q\", \"8-K\"]):\n",
    "    \"\"\"\n",
    "    Retrieve the most recent 10-K, 10-Q, and 8-K filings for a given CIK.\n",
    "    Returns a list of up to 3 filings (one per form type).\n",
    "    \"\"\"\n",
    "    base_url = f\"https://data.sec.gov/submissions/CIK{str(cik).zfill(10)}.json\"\n",
    "    headers = {\"User-Agent\": SEC_HEADER}\n",
    "    try:\n",
    "        resp = requests.get(base_url, headers=headers)\n",
    "        if resp.status_code != 200:\n",
    "            print(f\"Failed to fetch filings for CIK {cik}. Status code: {resp.status_code}\")\n",
    "            return []\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching filings for CIK {cik}: {e}\")\n",
    "        return []\n",
    "    filings_dict = {}\n",
    "    recent = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    forms_list = recent.get(\"form\", [])\n",
    "    accession_list = recent.get(\"accessionNumber\", [])\n",
    "    filing_dates = recent.get(\"filingDate\", [])\n",
    "    primary_docs = recent.get(\"primaryDocument\", [])\n",
    "    for i, form in enumerate(forms_list):\n",
    "        if form in forms and form not in filings_dict:\n",
    "            filing = {\n",
    "                \"form\": form,\n",
    "                \"date\": filing_dates[i] if i < len(filing_dates) else None,\n",
    "                \"accession\": accession_list[i] if i < len(accession_list) else None,\n",
    "                \"url\": f\"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession_list[i].replace('-', '')}/{primary_docs[i]}\" if i < len(accession_list) and i < len(primary_docs) else None,\n",
    "            }\n",
    "            filings_dict[form] = filing\n",
    "            if len(filings_dict) == len(forms):\n",
    "                break\n",
    "    return [filings_dict[form] for form in forms if form in filings_dict]\n",
    "\n",
    "\n",
    "\n",
    "def download_sec_filings(ticker, filings, output_dir):\n",
    "    \"\"\"\n",
    "    Download SEC filings and save them to the specified output directory.\n",
    "    Each file is named as: {ticker}_{form}_{date}.html\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filing in filings:\n",
    "        url = filing.get(\"url\")\n",
    "        form = filing.get(\"form\")\n",
    "        date = filing.get(\"date\")\n",
    "        if not url or not form or not date:\n",
    "            print(f\"Skipping incomplete filing for {ticker}: {filing}\")\n",
    "            continue\n",
    "        filename = f\"{ticker}_{form}_{date}.html\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            resp = requests.get(url, headers={\"User-Agent\": SEC_HEADER})\n",
    "            if resp.status_code == 200:\n",
    "                with open(filepath, \"wb\") as f:\n",
    "                    f.write(resp.content)\n",
    "                print(f\"Saved: {filepath}\")\n",
    "            else:\n",
    "                print(f\"Failed to download {url} (status {resp.status_code})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a024ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMZN', 'RDDT', 'WBD', 'MSFT', 'VWICX', 'CEG', 'JPM', 'LLY', 'UBER', 'BBJP', 'VNM']\n",
      "Fetching CIK for ticker: AMZN\n",
      "10-K | 2025-02-07 | https://www.sec.gov/Archives/edgar/data/1018724/000101872425000004/amzn-20241231.htm\n",
      "10-Q | 2025-10-31 | https://www.sec.gov/Archives/edgar/data/1018724/000101872425000123/amzn-20250930.htm\n",
      "8-K | 2025-11-20 | https://www.sec.gov/Archives/edgar/data/1018724/000110465925114647/tm2530638d3_8k.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\AMZN_10-K_2025-02-07.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\AMZN_10-Q_2025-10-31.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\AMZN_8-K_2025-11-20.html\n",
      "Fetching CIK for ticker: RDDT\n",
      "10-K | 2025-02-13 | https://www.sec.gov/Archives/edgar/data/1713445/000171344525000018/rddt-20241231.htm\n",
      "10-Q | 2025-10-31 | https://www.sec.gov/Archives/edgar/data/1713445/000171344525000227/rddt-20250930.htm\n",
      "8-K | 2025-10-30 | https://www.sec.gov/Archives/edgar/data/1713445/000171344525000225/rddt-20251030.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\RDDT_10-K_2025-02-13.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\RDDT_10-Q_2025-10-31.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\RDDT_8-K_2025-10-30.html\n",
      "Fetching CIK for ticker: WBD\n",
      "10-K | 2025-02-27 | https://www.sec.gov/Archives/edgar/data/1437107/000143710725000031/wbd-20241231.htm\n",
      "10-Q | 2025-11-06 | https://www.sec.gov/Archives/edgar/data/1437107/000143710725000216/wbd-20250930.htm\n",
      "8-K | 2025-12-05 | https://www.sec.gov/Archives/edgar/data/1437107/000119312525308759/d16580d8k.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\WBD_10-K_2025-02-27.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\WBD_10-Q_2025-11-06.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\WBD_8-K_2025-12-05.html\n",
      "Fetching CIK for ticker: MSFT\n",
      "10-K | 2025-07-30 | https://www.sec.gov/Archives/edgar/data/789019/000095017025100235/msft-20250630.htm\n",
      "10-Q | 2025-10-29 | https://www.sec.gov/Archives/edgar/data/789019/000119312525256321/msft-20250930.htm\n",
      "8-K | 2025-10-29 | https://www.sec.gov/Archives/edgar/data/789019/000119312525256310/msft-20251028.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\MSFT_10-K_2025-07-30.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\MSFT_10-Q_2025-10-29.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\MSFT_8-K_2025-10-29.html\n",
      "Fetching CIK for ticker: VWICX\n",
      "Ticker VWICX not found in SEC database.\n",
      "Fetching CIK for ticker: CEG\n",
      "10-K | 2025-02-18 | https://www.sec.gov/Archives/edgar/data/1868275/000186827525000023/ceg-20241231.htm\n",
      "10-Q | 2025-11-07 | https://www.sec.gov/Archives/edgar/data/1868275/000186827525000092/ceg-20250930.htm\n",
      "8-K | 2025-11-21 | https://www.sec.gov/Archives/edgar/data/1868275/000186827525000107/ceg-20251121.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\CEG_10-K_2025-02-18.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\CEG_10-Q_2025-11-07.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\CEG_8-K_2025-11-21.html\n",
      "Fetching CIK for ticker: JPM\n",
      "10-K | 2025-02-14 | https://www.sec.gov/Archives/edgar/data/19617/000001961725000270/jpm-20241231.htm\n",
      "10-Q | 2025-11-04 | https://www.sec.gov/Archives/edgar/data/19617/000162828025048859/jpm-20250930.htm\n",
      "8-K | 2025-10-22 | https://www.sec.gov/Archives/edgar/data/19617/000119312525246803/d33741d8k.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\JPM_10-K_2025-02-14.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\JPM_10-Q_2025-11-04.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\JPM_8-K_2025-10-22.html\n",
      "Fetching CIK for ticker: LLY\n",
      "10-K | 2025-02-19 | https://www.sec.gov/Archives/edgar/data/59478/000005947825000067/lly-20241231.htm\n",
      "10-Q | 2025-10-30 | https://www.sec.gov/Archives/edgar/data/59478/000005947825000254/lly-20250930.htm\n",
      "8-K | 2025-11-21 | https://www.sec.gov/Archives/edgar/data/59478/000005947825000271/lly-20251118.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\LLY_10-K_2025-02-19.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\LLY_10-Q_2025-10-30.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\LLY_8-K_2025-11-21.html\n",
      "Fetching CIK for ticker: UBER\n",
      "10-K | 2025-02-14 | https://www.sec.gov/Archives/edgar/data/1543151/000154315125000008/uber-20241231.htm\n",
      "10-Q | 2025-11-04 | https://www.sec.gov/Archives/edgar/data/1543151/000154315125000033/uber-20250930.htm\n",
      "8-K | 2025-11-04 | https://www.sec.gov/Archives/edgar/data/1543151/000154315125000030/uber-20251104.htm\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\UBER_10-K_2025-02-14.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\UBER_10-Q_2025-11-04.html\n",
      "Saved: C:/Users/patty/portfolio_files/SEC_filings\\UBER_8-K_2025-11-04.html\n",
      "Fetching CIK for ticker: BBJP\n",
      "Ticker BBJP not found in SEC database.\n",
      "Fetching CIK for ticker: VNM\n",
      "Ticker VNM not found in SEC database.\n"
     ]
    }
   ],
   "source": [
    "TICKER_LIST = EQUITY_LIST\n",
    "print(EQUITY_LIST)\n",
    "#OUTPUT_DIR_SEC_FILINGS\n",
    "for ticker in TICKER_LIST:\n",
    "    cik = get_cik(ticker)\n",
    "    if not cik:\n",
    "        continue\n",
    "    filings = get_sec_filings(cik)\n",
    "    for filing in filings:\n",
    "        print(f\"{filing['form']} | {filing['date']} | {filing['url']}\")\n",
    "    download_sec_filings(ticker, filings, OUTPUT_DIR_SEC_FILINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf5677",
   "metadata": {},
   "source": [
    "## Define Classes to Format the Output in a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860289cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.339940Z",
     "iopub.status.busy": "2025-11-15T16:43:06.339940Z",
     "iopub.status.idle": "2025-11-15T16:43:06.359281Z",
     "shell.execute_reply": "2025-11-15T16:43:06.359281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert markdown to Word document content\n",
    "def add_markdown_to_word(doc, markdown_text):\n",
    "    \"\"\"Convert markdown text to formatted Word document content\"\"\"\n",
    "    lines = markdown_text.split('\\n')\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        \n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Headers (# ## ###)\n",
    "        if line.startswith('#'):\n",
    "            level = len(line) - len(line.lstrip('#'))\n",
    "            text = line.lstrip('#').strip()\n",
    "            doc.add_heading(text, level=min(level, 9))\n",
    "        \n",
    "        # Tables (|...)\n",
    "        elif '|' in line and i + 1 < len(lines) and '|' in lines[i + 1]:\n",
    "            # Parse table\n",
    "            table_lines = [line]\n",
    "            i += 1\n",
    "            # Skip separator line\n",
    "            if '---' in lines[i] or ':-:' in lines[i]:\n",
    "                i += 1\n",
    "            # Get table rows\n",
    "            while i < len(lines) and '|' in lines[i]:\n",
    "                table_lines.append(lines[i])\n",
    "                i += 1\n",
    "            \n",
    "            # Create table\n",
    "            headers = [cell.strip() for cell in table_lines[0].split('|') if cell.strip()]\n",
    "            num_cols = len(headers)\n",
    "            num_rows = len(table_lines)\n",
    "            \n",
    "            table = doc.add_table(rows=num_rows, cols=num_cols)\n",
    "            table.style = 'Light Grid Accent 1'\n",
    "            \n",
    "            # Add headers\n",
    "            for j, header in enumerate(headers):\n",
    "                cell = table.rows[0].cells[j]\n",
    "                cell.text = header\n",
    "                cell.paragraphs[0].runs[0].bold = True\n",
    "            \n",
    "            # Add data rows\n",
    "            for row_idx in range(1, len(table_lines)):\n",
    "                cells = [cell.strip() for cell in table_lines[row_idx].split('|') if cell.strip()]\n",
    "                for col_idx, cell_text in enumerate(cells):\n",
    "                    if col_idx < num_cols:\n",
    "                        table.rows[row_idx].cells[col_idx].text = cell_text\n",
    "            \n",
    "            doc.add_paragraph()  # Add space after table\n",
    "            continue\n",
    "        \n",
    "        # Bullet points (- or *)\n",
    "        elif line.strip().startswith(('- ', '* ', '• ')):\n",
    "            text = line.strip()[2:].strip()\n",
    "            # Handle bold/italic in bullet points\n",
    "            p = doc.add_paragraph(style='List Bullet')\n",
    "            add_formatted_text(p, text)\n",
    "        \n",
    "        # Numbered lists (1. 2. etc)\n",
    "        elif re.match(r'^\\d+\\.\\s', line.strip()):\n",
    "            text = re.sub(r'^\\d+\\.\\s', '', line.strip())\n",
    "            p = doc.add_paragraph(style='List Number')\n",
    "            add_formatted_text(p, text)\n",
    "        \n",
    "        # Bold text with **\n",
    "        elif '**' in line or '__' in line:\n",
    "            p = doc.add_paragraph()\n",
    "            add_formatted_text(p, line)\n",
    "        \n",
    "        # Regular paragraph\n",
    "        else:\n",
    "            p = doc.add_paragraph()\n",
    "            add_formatted_text(p, line)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "def add_formatted_text(paragraph, text):\n",
    "    \"\"\"Add text with bold/italic markdown formatting to a paragraph\"\"\"\n",
    "    # Handle **bold** and __bold__\n",
    "    parts = re.split(r'(\\*\\*.*?\\*\\*|__.*?__|`.*?`)', text)\n",
    "    \n",
    "    for part in parts:\n",
    "        if not part:\n",
    "            continue\n",
    "        \n",
    "        if part.startswith('**') and part.endswith('**'):\n",
    "            run = paragraph.add_run(part[2:-2])\n",
    "            run.bold = True\n",
    "        elif part.startswith('__') and part.endswith('__'):\n",
    "            run = paragraph.add_run(part[2:-2])\n",
    "            run.bold = True\n",
    "        elif part.startswith('`') and part.endswith('`'):\n",
    "            run = paragraph.add_run(part[1:-1])\n",
    "            run.font.name = 'Courier New'\n",
    "        else:\n",
    "            paragraph.add_run(part)\n",
    "\n",
    "\n",
    "def sort_markdown_table_by_industry(markdown_text):\n",
    "    lines = markdown_text.split('\\n')\n",
    "    table_start = None\n",
    "    table_end = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and table_start is None:\n",
    "            table_start = i\n",
    "        elif table_start is not None and ('|' not in line or not line.strip()):\n",
    "            table_end = i\n",
    "            break\n",
    "    if table_start is None or table_end is None:\n",
    "        return markdown_text  # No table found\n",
    "\n",
    "    header = lines[table_start]\n",
    "    separator = lines[table_start + 1]\n",
    "    rows = lines[table_start + 2:table_end]\n",
    "    # Find the index of the Industry/Category column\n",
    "    columns = [col.strip().lower() for col in header.split('|')]\n",
    "    try:\n",
    "        industry_idx = columns.index('industry')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            industry_idx = columns.index('category')\n",
    "        except ValueError:\n",
    "            return markdown_text  # No industry/category column\n",
    "\n",
    "    # Sort rows by industry/category\n",
    "    def get_industry(row):\n",
    "        cells = [cell.strip() for cell in row.split('|')]\n",
    "        return cells[industry_idx] if industry_idx < len(cells) else ''\n",
    "    rows_sorted = sorted(rows, key=get_industry)\n",
    "\n",
    "    # Rebuild the markdown\n",
    "    sorted_table = [header, separator] + rows_sorted\n",
    "    lines = lines[:table_start] + sorted_table + lines[table_end:]\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2944b10",
   "metadata": {},
   "source": [
    "## Generate Analysis for Each Stock in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f20522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T16:43:06.364029Z",
     "iopub.status.busy": "2025-11-15T16:43:06.364029Z",
     "iopub.status.idle": "2025-11-15T16:43:06.784506Z",
     "shell.execute_reply": "2025-11-15T16:43:06.784506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Perplexity API for equities for AMZN (1/11)...\n",
      "Querying Perplexity API for equities for RDDT (2/11)...\n",
      "Querying Perplexity API for equities for WBD (3/11)...\n",
      "Querying Perplexity API for equities for MSFT (4/11)...\n",
      "Querying Perplexity API for equities for VWICX (5/11)...\n",
      "Querying Perplexity API for equities for CEG (6/11)...\n",
      "Querying Perplexity API for equities for JPM (7/11)...\n",
      "Querying Perplexity API for equities for LLY (8/11)...\n",
      "Querying Perplexity API for equities for UBER (9/11)...\n",
      "Querying Perplexity API for equities for BBJP (10/11)...\n",
      "Querying Perplexity API for equities for VNM (11/11)...\n",
      "\n",
      "============================================================\n",
      "✅ Completed processing 11 equities\n",
      "Reports saved to: C:/Users/patty/portfolio_files/Individual_stock_analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS, exist_ok=True)  \n",
    "\n",
    "# Initialize Perplexity client\n",
    "client = PerplexityClient(api_key=API_KEY)\n",
    "counter = 0\n",
    "# Process each equity\n",
    "for equity in EQUITY_LIST:\n",
    " \n",
    "    # Construct prompt with equity ticker and template from file\n",
    "    prompt = f\"For the equity {equity} {PROMPT_TEMPLATE}\"\n",
    "    \n",
    "    # Check if report already exists for today\n",
    "    date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    output_filename = f\"Equity Report - {equity} {date_str}.docx\"\n",
    "    output_path = os.path.join(OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS, output_filename)\n",
    " \n",
    "    if os.path.exists(output_path):\n",
    "        #print(f\"⏭️  Skipping {equity} - report already exists for {date_str}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Query the LLM\n",
    "        print(f\"Querying Perplexity API for equities for {equity} ({counter + 1}/{len(EQUITY_LIST)})...\")\n",
    "        # print(\"Using prompt:\",prompt   )\n",
    "\n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "        counter += 1\n",
    "        \n",
    "        # Create Word document\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"Market Outlook Report - {equity}\", 0)\n",
    "        doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "        doc.add_paragraph()\n",
    "        \n",
    "        # Convert markdown to Word formatting\n",
    "        add_markdown_to_word(doc, generated_text)\n",
    "        \n",
    "        # Add prompt at the end\n",
    "        doc.add_paragraph()\n",
    "        doc.add_heading(\"Prompt Used:\", level=2)\n",
    "        doc.add_paragraph(prompt)\n",
    "        \n",
    "        # Save the document\n",
    "        doc.save(output_path)\n",
    "        # print(f\"✅ Saved: {output_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {equity}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✅ Completed processing {len(EQUITY_LIST)} equities\")\n",
    "print(f\"Reports saved to: {OUTPUT_DIR_INDIVIDUAL_STOCK_ANALYSIS}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee5794",
   "metadata": {},
   "source": [
    "## Generate Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91aa2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing portfolio for select equities and generating individual reports\n",
      "⏭️  Skipping portfolio - report already exists for 2025-12-05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from docx.shared import Pt\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_PORTFOLIO_ANALYSIS, exist_ok=True)\n",
    "\n",
    "# Initialize Perplexity client with API key from environment variable\n",
    "client = PerplexityClient(api_key=API_KEY)\n",
    "\n",
    "# Generate a single prompt for the entire EQUITY_LIST using PROMPT_PORTFOLIO_ANALYSIS\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "output_filename = f\"Portfolio Report {date_str}.docx\"\n",
    "output_path = os.path.join(OUTPUT_DIR_PORTFOLIO_ANALYSIS, output_filename)\n",
    "\n",
    "# Combine all equities into a single string (comma separated, or as a list)\n",
    "equity_str = ', '.join(EQUITY_LIST)\n",
    "\n",
    "# Read the portfolio prompt template from file (already done above)\n",
    "# with open(PROMPT_PORTFOLIO_ANALYSIS, 'r') as f:\n",
    "#     PROMPT_PORTFOLIO_TEMPLATE = f.read().strip()\n",
    "\n",
    "# Construct the prompt for the entire list\n",
    "prompt = f\"For the equities {equity_str} {PROMPT_PORTFOLIO_TEMPLATE}\"\n",
    "print(f\"Processing portfolio for select equities and generating individual reports\")\n",
    "\n",
    "# Check if report already exists for today\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"⏭️  Skipping portfolio - report already exists for {date_str}\")\n",
    "else:\n",
    "    try:\n",
    "        # Query the LLM\n",
    "        # print(f\"Querying Perplexity API for portfolio...\")\n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "\n",
    "        # Sort the markdown table by Industry/Category\n",
    "        sorted_markdown = sort_markdown_table_by_industry(generated_text)\n",
    "\n",
    "        # Create Word document\n",
    "        doc = Document()\n",
    "        doc.add_heading(f\"Market Outlook Portfolio Report\", 0)\n",
    "        doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "        doc.add_paragraph()\n",
    "\n",
    "        # Convert markdown to Word formatting\n",
    "        add_markdown_to_word(doc, sorted_markdown)\n",
    "\n",
    "        # Apply formatting to the last table (smaller font, no bold, remove asterisks)\n",
    "        if doc.tables:\n",
    "            table = doc.tables[-1]\n",
    "            for row in table.rows:\n",
    "                for cell in row.cells:\n",
    "                    for paragraph in cell.paragraphs:\n",
    "                        for run in paragraph.runs:\n",
    "                            run.font.size = Pt(8)\n",
    "                            run.bold = False\n",
    "                            run.text = run.text.replace('*', '')\n",
    "\n",
    "        # Add prompt at the end\n",
    "        doc.add_paragraph()\n",
    "        doc.add_heading(\"Prompt Used:\", level=2)\n",
    "        doc.add_paragraph(prompt)\n",
    "\n",
    "        # Save the document\n",
    "        doc.save(output_path)\n",
    "        print(f\"✅ Saved: {output_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing portfolio: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f8e64",
   "metadata": {},
   "source": [
    "## Utility to Format Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fd722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility to sort markdown table by a given column and remove bolds/asterisks ---\n",
    "def sort_and_clean_markdown_table(markdown_text):\n",
    "    sort_column_name = 'Current Consensus Analyst Rating'\n",
    "    lines = markdown_text.split('\\n')\n",
    "    table_start = None\n",
    "    table_end = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and table_start is None:\n",
    "            table_start = i\n",
    "        elif table_start is not None and ('|' not in line or not line.strip()):\n",
    "            table_end = i\n",
    "            break\n",
    "    if table_start is None or table_end is None:\n",
    "        return markdown_text  # No table found\n",
    "\n",
    "    header = lines[table_start]\n",
    "    separator = lines[table_start + 1]\n",
    "    rows = lines[table_start + 2:table_end]\n",
    "\n",
    "    # Remove bolds and asterisks from header and rows\n",
    "    def clean(text):\n",
    "        return text.replace('**', '').replace('*', '').replace('__', '')\n",
    "    header_clean = clean(header)\n",
    "    rows_clean = [clean(row) for row in rows]\n",
    "    columns = [col.strip().lower() for col in header_clean.split('|')]\n",
    "    try:\n",
    "        sort_idx = columns.index(sort_column_name.lower())\n",
    "    except ValueError:\n",
    "        return '\\n'.join([header_clean, separator] + rows_clean + lines[table_end:])\n",
    "    def get_sort_key(row):\n",
    "        cells = [cell.strip() for cell in row.split('|')]\n",
    "        return cells[sort_idx] if sort_idx < len(cells) else ''\n",
    "    rows_sorted = sorted(rows_clean, key=get_sort_key)\n",
    "    sorted_table = [header_clean, separator] + rows_sorted\n",
    "    lines = lines[:table_start] + sorted_table + lines[table_end:]\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce53cc",
   "metadata": {},
   "source": [
    "## Generate Ratings Change Report and Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d8e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: Ratings Change Report 2025-12-05.docx in C:/Users/patty/portfolio_files/Portfolio_analysis\n"
     ]
    }
   ],
   "source": [
    "# Generate Ratings Change Report for select equities\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR_PORTFOLIO_ANALYSIS, exist_ok=True)\n",
    "\n",
    "date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "output_filename = f\"Ratings Change Report {date_str}.docx\"\n",
    "output_path = os.path.join(OUTPUT_DIR_PORTFOLIO_ANALYSIS, output_filename)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Ratings Change Report\", 0)\n",
    "doc.add_paragraph(f\"Perplexity Sonar Pro Model Generated: {date_str}\")\n",
    "doc.add_paragraph()\n",
    "\n",
    "#Summary table API call time: {t1-t0:.2f} seconds\n",
    "# --- Individual equity details ---\n",
    "\n",
    "for equity in EQUITY_LIST:\n",
    "    prompt = f\"For the equity {equity} {PROMPT_RATINGS_CHANGE_TEMPLATE}\"\n",
    "    doc.add_heading(f\"{equity}\", level=1)\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        generated_text = client.chat(prompt, model=MODEL)\n",
    "        t1 = time.time()\n",
    "        add_markdown_to_word(doc, generated_text)\n",
    "        # print(f\"{equity} API call time: {t1-t0:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        doc.add_paragraph(f\"❌ Error processing {equity}: {e}\")\n",
    "    doc.add_paragraph()  # Space between equities\n",
    "\n",
    "# Add prompt template at the end for reference\n",
    "doc.add_heading(\"Prompt Template Used:\", level=2)\n",
    "doc.add_paragraph(PROMPT_RATINGS_CHANGE_TEMPLATE)\n",
    "\n",
    "doc.save(output_path)\n",
    "print(f\"✅ Saved: {output_filename} in {OUTPUT_DIR_PORTFOLIO_ANALYSIS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dbe42",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
